# ============================================================================
# 2013-04-07 (Sunday) 00:58 IST
#
# Get beta click database and start writing analysis code for it.

cd analysis/workspace

wget http://spacewarps.org.s3.amazonaws.com/data-export/spacewarps-2013-04-06_20-07-28.tar.gz

tar xvfz spacewarps-2013-04-06_20-07-28.tar.gz

ls spacewarps-2013-04-06_20-07-28/ouroboros_staging/
# spacewarp_classifications.bson          spacewarp_subjects.bson
# spacewarp_classifications.metadata.json spacewarp_subjects.metadata.json

# These are files to be read into a mongoDB, using mongodbrestore.

# Needs pymongo... pip install? Yep - done

# Also need binary installation of mongodb, from mongodb.org
# Downloaded to software, linked to ~/bin

mongorestore spacewarps-2013-04-06_20-07-28
# Sun Apr  7 01:23:48.133 kern.sched unavailable
# couldn't connect to [127.0.0.1] couldn't connect to server 127.0.0.1:27017

# Hmm. Looks beyond my pay grade.
# Try from python:

cd spacewarps-2013-04-06_20-07-28/
python ../../swap/mongodb.py

Traceback (most recent call last):
  File "../../swap/mongodb.py", line 23, in <module>
    m = MongoDB()
  File "../../swap/mongodb.py", line 13, in __init__
    self.client = MongoClient('localhost', 27017)
  File "/usr/local/Cellar/python/2.7.2/lib/python2.7/site-packages/pymongo/mongo_client.py", line 336, in __init__
    raise ConnectionFailure(str(e))
pymongo.errors.ConnectionFailure: could not connect to localhost:27017: [Errno 61] Connection refused

# Need to start mongodb server in the background:

mongod --dbpath . &

# Now python runs ok:

python ../../swap/mongodb.py
# Collection(Database(MongoClient('localhost', 27017), u'ouroboros_staging'), u'spacewarp_subjects.0')
# Collection(Database(MongoClient('localhost', 27017), u'ouroboros_staging'), u'spacewarp_classifications.0')

# What are these things?!
# OK, open up python session and start playing.

>>> import swap
>>> m = swap.MongoDB()
>>> m.subjects
Collection(Database(MongoClient('localhost', 27017), u'ouroboros_staging'), u'spacewarp_subjects')
>>> m.subjects.find()
<pymongo.cursor.Cursor object at 0x101220f50>

# Interesting.

>>> m.subjects.find_one({'zooniverse_id' : 'ASW0000002'})
{u'project_id': ObjectId('5101a1341a320ea77f000001'),
u'classification_count': 523, u'created_at': datetime.datetime(2013, 4,
4, 20, 29, 18, 949000), u'random': 0.5465496445414518, u'updated_at':
datetime.datetime(2013, 4, 4, 20, 29, 18, 975000), u'state':
u'complete', u'trending': 3, u'coords': [], u'location': {u'thumbnail':
u'', u'standard': u''}, u'zooniverse_id': u'ASW0000002',
u'workflow_ids': [ObjectId('5101a1361a320ea77f000002')], u'_id':
ObjectId('5101a1931a320ea77f000004'), u'tutorial': True, u'metadata':
{}}

# OK cool - here's a clue to the subject schema, and the metadata on subject
# ASW0000002.

# How about a non-tutorial one?
>>> m.subjects.find_one({'zooniverse_id' : 'ASW0000004'}) {u'_id':
ObjectId('515de29fe4bb216427000001'), u'classification_count': 13,
u'created_at': datetime.datetime(2013, 4, 4, 20, 29, 19, 372000),
u'activated_at': datetime.datetime(2013, 4, 4, 20, 32, 51, 886000),
u'updated_at': datetime.datetime(2013, 4, 4, 20, 29, 19, 398000),
u'random': 0.1047423015104475, u'project_id':
ObjectId('5101a1341a320ea77f000001'), u'state': u'active',
u'zooniverse_id': u'ASW0000004', u'workflow_ids':
[ObjectId('5101a1361a320ea77f000002')], u'location': {u'thumbnail':
u'http://www.spacewarps.org/subjects/thumbnail/CFHTLS_002_0530_gri.png',
u'standard':
u'http://www.spacewarps.org/subjects/standard/CFHTLS_002_0530_gri.png'},
u'group_id': ObjectId('5154a3783ae74086ab000001'), u'metadata': {u'id':
u'CFHTLS_002_0530'}}

# Nice! There's the actual image name, from Anu. And this URL is open -
# volunteers can grab those any time if they want to model them elsewhere.
# Just need to expose that on the site somewhere.

# Anyway, what about classifications?

>>> m.classifications.find_one()
{u'_id': ObjectId('515de3a9390c056085000416'), u'created_at':
datetime.datetime(2013, 4, 4, 20, 33, 45), u'updated_at':
datetime.datetime(2013, 4, 4, 20, 33, 45, 885000), u'user_ip':
u'163.1.174.106', u'workflow_id': ObjectId('5101a1361a320ea77f000002'),
u'subjects': [], u'subject_ids': [ObjectId('515dd45de4bb21597c00026c')],
u'project_id': ObjectId('5101a1341a320ea77f000001'), u'annotations':
[{u'finished_at': u'Thu, 04 Apr 2013 20:32:19 GMT', u'started_at': u'Thu, 04
Apr 2013 19:57:45 GMT'}, {u'user_agent': u'Mozilla/5.0 (Macintosh; Intel Mac
OS X 10_7_5) AppleWebKit/537.31 (KHTML, like Gecko) Chrome/26.0.1410.43
Safari/537.31'}]}

>>> m.classifications.find({'_id':'515de3a9390c056085000416'})
# <pymongo.cursor.Cursor object at 0x10122c050>

# Hmm. A cursor seems to be some sort of cursor. Might need a bit of help
# learning how this works!

# Plan:
#
# Make a list of operations that I want to do,
# and ask for a suggested example command from Amit?
#
# 1) Return a list of users as an array of strings
#
# 2) For a given user, return the IDs of all the training subjects they classified
#     Presumably this array will be time-ordered?
#
# 3) For a given user and training subject ID, return the value 1 if they succeeded in recognising it, 0 if not

# Issued.


# 2013-04-18 (Thursday) 12:04 BST
#
# datetime objects are interesting! See http://docs.python.org/2/library/datetime.html
#
# >>> import datetime
# >>> print datetime.datetime(2013, 4, 4, 20, 29, 18, 949000)
# 2013-04-04 20:29:18.949000
# >>> t1 = datetime.datetime(2013, 4, 4, 20, 29, 18, 949000)
# >>> t2 = datetime.datetime(2013, 4, 5, 8, 15, 23, 543000)
# >>> t2 - t1
# datetime.timedelta(0, 42364, 594000)
# >>> t1 > t2
# False
# >>> t1 <= t2
# True

# Perfect!

# ============================================================================
# 2013-04-22 (Monday) 23:24 BST

# Getting data out of mongodb is not so intuitive. Wrapped it up in
# python so that I can just do, eg

cd workspace
python ../swap/mongodb.py

# But I cannot do even the most basic things - so I've written down what
# I want to do in plausible python, for Amit to advise on!

# ============================================================================
# 2013-04-24 (Wednesday) 10:18 BST
#
# Great session with Amit yesterday solving all my db access problems!
# He says that on the Zooniverse system, the correct db is always online,
# so we should just connect to the client. That means that all of this
# wrapper I wrote is redundant - but I preserve it here, for reference:

#     self.dumpname = dumpname
#
#     # Keep a record of what goes on:
#     self.logfilename = os.getcwd()+'/'+self.dumpname+'.log'
#     self.logfile = open(self.logfilename,"w")
#
#     # Start the Mongo server in the background:
#     subprocess.call(["mongorestore",self.dumpname],stdout=self.logfile,stderr=self.logfile)
#     os.chdir(self.dumpname)
#     self.cleanup()
#     self.process = subprocess.Popen(["mongod","--dbpath","."],stdout=self.logfile,stderr=self.logfile)
#
#     # Check everything is working:
#     if self.process.poll() == None: print "MongoDB: server is up and running"
#
#     # Connect to the Mongo:
#     self.client = MongoClient('localhost', 27017)
#     self.db = self.client['ouroboros_staging']
#
#     self.subjects = self.db['spacewarp_subjects']
#     self.classifications = self.db['spacewarp_classifications']

# Followed by, later,
#     m.terminate()

# Worked example gives the following result, from the initial beta DB:

# Counted  7564  classifications, that each look like:
# ('2013-04-06 19:54:42.146000', '5065ff08d10d244cd10029ba', '515de2efe4bb21642700019a', 'test', 'NOT')

# ============================================================================
# 2013-04-29 (Monday) 17:03 BST

# OK, got SWAP working in its simplest incarnation.
# REady to do some experiments!

# Standard setup is this on: agents learn, but set PD=PL=50%, initially.
SWAP.py CFHTLS-beta_P50.config

# Aprajita asks, do we have to learn? Why not assume one set of P's and
# stick with them? Get off to a fsater start?
SWAP.py CFHTLS-beta_no-learning_P50.config
# Random classifiers get nowhere!

SWAP.py CFHTLS-beta_no-learning_P90.config
# Big jumps up and down in probability, lots of false positives.


# OK, so back to learning. How about we be less pessimistic about people's
# talents?
SWAP.py CFHTLS-beta_P90.config
# Not bad - Christmas tree is broader. FP rate higher, but got some sims in
# the detection zone now.

# More measured. Crowd divided between two groups?
#    The Herd: PD = 0.9, PL = U(0:1)
# Enthusiasts: PD = U(0.2:0.6), PL = U(0.6:1.0)
SWAP.py CFHTLS-beta_P70.config


# One issue with this LENS or NOT analysis is the hard edged estimation of PD
# and PL. Early classifications can have a significant impact... Hmm. 70-70
# seems like a reasonable starting point.


# Wishlist for mock survey:

# - Difficulty variation              DONE
# - PD, PL capped at 0.99             DONE
# - Realistic PDFs for Nc, PD, PL     DONE

# ============================================================================
# 2013-05-06 (Monday) 12:40 BST

# Wishlist for mock survey (continued):

# - Completeness, purity calculated   DONE 2013-05-06
# - Detected/rejected subjects        DONE 2013-05-06
# - Retired/promoted subjects         DONE 2013-05-06
# - Candidate IDs output              DONE 2013-05-06

# OK, great! Now we just need to be able to do low cost
# batch processing.


# ============================================================================
# 2013-05-07 (Tuesday) 09:43 BST

# Testing new database!

# Download:

set url = "https://zooniverse-code.s3.amazonaws.com/databases/2013-05-07/ouroboros_projects/spacewarp_2013-05-07.tar.gz?AWSAccessKeyId=AKIAJHHZ7KLFECQKTS7A&Expires=1368548396&Signature=as2nCaTgD9ctFLIHZrxj%2FrnQJoo%3D"

set dbfile = `echo "$url" | cut -d '?' -f1 | cut -d'/' -f7`
set logfile = ${dbfile:r:r}.wget.log
wget -O $dbfile "$url" >& $logfile

# Unpack:
tar xvfz $dbfile

set db = $dbfile:r:r

# First need to kill any old servers:
set pid = `ps -e | grep 'mongod --dbpath' | \
                   grep -v 'grep' | head -1 | awk '{print $1}'`
if ($#pid > 0) kill $pid

# Start new mongo server in its own directory, out of the way:
mkdir -p mongo
chdir mongo
mongod --dbpath . &
chdir ..

# Now restore the new database:
mongorestore --drop --db ouroboros_staging $db

# Probably should script this? Maybe?


# Try running SWAP:

SWAP.py CFHTLS-test.config >& CFHTLS-test.log

# SWAP: interpreting classifications...
# SWAP: total no. of classifications processed:  0


# Scripted! Just need to download db tarball manually:

SWIPE.csh spacewarp_2013-05-07.tar.gz


# ============================================================================
# 2013-05-07 (Tuesday) 18:36 BST

# Control of retirement from afar! Coooooool.

# Email from Michael Parrish:


# Hi Phil,
# 
# I'm attaching an example administration client script (in python) along
# with the documentation for administration endpoints. The script depends
# on the requests library, which you can install with `pip install
# requests`.
# 
# The admin account in the script is active -- feel free to
# retire/activate some subjects to make sure it's working for you.
# 
# Since this is all new code, there may still be some rough edges to work
# through, so please let me know if you have questions/problems.
# 
# -Michael
# 
# 
# 
# Administration:
# 
# Administration requests are authenticated with a combination of a
# password, a private key, a public key, and a sequence identifier.
# 
# 
# Administrators:
# 
# Accounts are created by request. A password, and private key will be
# supplied.
# 
# 
# Session:
# 
# A session begins by logging in with a POST request to /admin/login with
# { name: 'your admin name', password: 'your admin password' }
# 
# A successful login responds with a new public_key.
# 
# 
# Requests:
# 
# After establishing a session, requests can be made by signing each
# request with the name of the administrator and request key.
# 
# Request keys are generated by combining the public and private keys as
# well as a sequence identifier.
# 
# At the beginning of a session, the sequence identifier is 1. Each
# request increments this number.
# 
# In the case of an unauthorized request, sequence identifiers will no
# longer match causing the session to terminate.
# 
# If a session terminates, a new login request must be sent to restart the
# session with a new public key.
# 
# 
# Login Limits:
# 
# More than 10 unsuccessful login attempts within an hour will temporarily
# block logins by the administrator account. More than 100 unsuccessful
# login attempts within an hour will disable the administrator account. A
# developer will have to reactivate it.
# 
# Requests:
# 
# Administration requests are rate limited to less than 1,000 per hour.
# All requests, successful or not, are logged for security purposes.
# 
# Example code:
# 
# Subject Administration
# 
# Method  Action      Path                                                Params
# PUT     activate    /admin/projects/:project_id/subjects/:id/activate   { }
# PUT     retire      /admin/projects/:project_id/subjects/:id/retire     { }
# PUT     pause       /admin/projects/:project_id/subjects/:id/pause      { }
# PUT     resume      /admin/projects/:project_id/subjects/:id/resume     { }


# OK, got it! Wrote SWITCH.py to read in a list of subject IDs, and 
# then make put requests to retire them. 

# First run SWAP with low rejection threshold to get a bunch of
# retirements to do:

SWAP.py CFHTLS-SWITCH-test.config 

# SWAP: interpreting classifications...
# SWAP: 
# SWAP: total no. of classifications processed:  37
# SWAP: saving newly retired subject IDs...
# SWAP: 19 lines written to /Users/pjm/public_html/SpaceWarps/Science/analysis/workspace/CFHTLS-SWITCH-test_2013-05-07/CFHTLS-SWITCH-test_2013-05-07_retire_these.txt

# Good - now SWITCH them:

set retirees = /Users/pjm/public_html/SpaceWarps/Science/analysis/workspace/CFHTLS-SWITCH-test_2013-05-07/CFHTLS-SWITCH-test_2013-05-07_retire_these.txt

# SWITCH: retiring subjects listed in  /Users/pjm/public_html/SpaceWarps/Science/analysis/workspace/CFHTLS-SWITCH-test_2013-05-07/CFHTLS-SWITCH-test_2013-05-07_retire_these.txt
# SWITCH: looks like we have 19  subjects to retire
# SWITCH: doing a dry run
# result = client.put('/projects/spacewarp/subjects/ASW000075q/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000arx/retire')
# result = client.put('/projects/spacewarp/subjects/ASW00005js/retire')
# result = client.put('/projects/spacewarp/subjects/ASW000082p/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000hlt/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000by9/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000a4m/retire')
# result = client.put('/projects/spacewarp/subjects/ASW00008wq/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000wlr/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000c6t/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000w51/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000kx4/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000s3v/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000l4y/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000d6r/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000b6n/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000tc7/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000hs9/retire')
# result = client.put('/projects/spacewarp/subjects/ASW0000kig/retire')

# OK, looks good - give it a try!

SWITCH.py $retirees

# Whoah - success?
# 
# SWITCH: retiring subjects listed in  /Users/pjm/public_html/SpaceWarps/Science/analysis/workspace/CFHTLS-SWITCH-test_2013-05-07/CFHTLS-SWITCH-test_2013-05-07_retire_these.txt
# SWITCH: looks like we have 19  subjects to retire
# 
# ...
# 
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(0)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(1)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(2)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(3)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(4)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(5)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(6)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(7)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(8)
# 'instancemethod' object is not subscriptable(0)
# 'instancemethod' object is not subscriptable(1)
# 'instancemethod' object is not subscriptable(2)
# 'NoneType' object is not iterable(9)
# ASW0000kig False
# ======================================================================

# Check with Michael!! :-)

# Yep, all good after changing response.json to response.json()

# ======================================================================
# 2013-05-08 (Wednesday) 14:29 BST

# Launch day! :-)
# First batch of classifications from Michael. First tidy away all the
# beta work... and also the SWITCH test:

mkdir -p Beta
mv *beta* Beta/
mv spacewarps-2013-04-06_20-07-28* Beta/

mkdir -p SWITCH-test
mv *-SWITCH* SWITCH-test/
mv spacewarp_* SWITCH-test/
mv CFHTLS* SWITCH-test/

# Now make a working directory:
mkdir -p 2013-05-08
cd 2013-05-08

# OK, get new db:

set url = "https://zooniverse-code.s3.amazonaws.com/databases/2013-05-08/ouroboros_projects/spacewarp_2013-05-08.tar.gz?AWSAccessKeyId=AKIAJHHZ7KLFECQKTS7A&Expires=1368612013&Signature=QRK%2BOV37H6khTqgqoTu0z%2FLO%2F2s%3D"

set dbfile = `echo "$url" | cut -d '?' -f1 | cut -d'/' -f7`
set logfile = ${dbfile:r:r}.wget.log
wget -O $dbfile "$url" >& $logfile

# OK, SWIPE this:

SWIPE.csh $dbfile

# Good! This script should write a config file.

SWAP.py startup.config

# Nice - 10,000 classifications of 8000 subjects by 300 people. Crowd
# look very similar to beta! Result :-)

# ======================================================================
# 2013-05-09 (Thursday) 09:46 BST

# Gosh - half a million classifications in the first day!
# Better get this code working at scale - and fast.

# OK, SWAPSHOP is operational and checked in.

# Run on 1st 300,000 classifications!
# Just did:

SWAPSHOP.csh

# Got 117 candidates and 131 false negatives from first 300,000 
# classifications, in 2013-05-09

# Made plot of just false negatives for AV - quite some uncertainty,
# subjects move back and forth quite a lot. Agents are overconfident!


# Try shifting thresholds to 0.4 and 1e-7 (symmetrical). How many
# retirements? Completeness stats?

# Edited swap/startup.config, then ran:

time SWAPSHOP.csh -s CFHTLS-strict -f --fast

# --fast is no animation, so no plots until the end!

# Looks like its about 20s per batch, increasing with time though. 
# 11 batches total, plus plots, takes 8.5 mins.

# STill getting 17% false negatives, and with only 18000 retirements!


# Try a cheap version of Surhud's idea - ignore the first few clicks?
# Coded as ignore if agent.NT <= a_few_at_the_start where this 
# refers to a few training images. Lets try an extreme version with
# a_few_at_the_start = 10!

time SWAPSHOP.csh -s CFHTLS-reallystrict -f --fast

# Same number of classifiers/agents, but now many will stay at 0.5
# because they never leave... 10 training images requires about 30
# images total in the standard stream. The agent history only gets
# updated for classifications that count

# OK, I get 11500 retirements, and down to 13% false negatives
# The total number of classifications is now 267000, so we lose about
# 100k to the traiing programme! Candidates are still at 96, as with
# strict routine.

# Look at the images! Well, ones that are still negative:

mkdir training_false_negatives
set repo = ../2013-05-09/training_false_negatives

foreach url ( `cat CFHTLS-reallystrict_2013-05-09_01:38:24/CFHTLS-reallystrict_2013-05-09_01:38:24_training_false_negatives.txt` )
    set png = $url:t
    cp $repo/$png training_false_negatives/.
end

# OK, we had all but 3 already.
# cp: ../2013-05-09/training_false_negatives/5183f151e4bb2102190044e2.png: No such file or directory
# cp: ../2013-05-09/training_false_negatives/5183f151e4bb210219007187.png: No such file or directory
# cp: ../2013-05-09/training_false_negatives/5183f151e4bb210219004b03.png: No such file or directory

# What do *these* look like?

# Mostly LRGs with rings hidden in depths. All fairly tricky.
# ======================================================================
# 2013-05-10 (Friday) 12:17 BST

# New db! Try analysing with the really straict settings that are
# currently checked in:

SWIPE.csh spacewarp_2013-05-10.tar.gz

time SWAPSHOP.csh -s CFHTLS-reallystrict -f --fast

# Hmm - weird. 1.08 million classifications, but report only shows 
# 396281! Still, 15% lenses missed, 82% completeness, 99.8% purity
# in sims vs duds. 33078 subjects to retire. Leave the candidates in
# to be inspected more often! FPs are not a problem.

# Try running without the 10-subject training period.

time SWAPSHOP.csh -s CFHTLS-strict -f --fast

# OK, hmm. Seems I am counting wrong!
# Yep - switched to agents counting all classifications, 
# but subjects only counts that matter to them.

# OK, last tests: try really strict with 95% detection threshold, 
# and retirement only at low probability end.

time SWAPSHOP.csh -s CFHTLS-reallystrict95 -f --fast -d

# Affects number of detections, but not enormously they are all highly
# classified at this point


# Talked to Amit about using simFound annotation for sims!
# Implemented, lets compare with strict (reset thresholds):

time SWAPSHOP.csh -s CFHTLS-strict-simFound -f --fast

# Hmm - looks very odd. Save and investigate...
# Put in a print statement in mongodb.digest - what's going on?

time SWAPSHOP.csh -s CFHTLS-strict-simFound -f --fast -t 1

# OK, ran with verbose and one_by_one. Results seem plausible,
# but there aren't too many hits on the sims!

# In db.digest: kind,N_markers,simFound,result,truth =  sim 0 false NOT LENS
# SWAP: --------------------------------------------------------------------------
# SWAP: Subject 5183f151e4bb210219005ac5 was classified by 63.250.229.206
# SWAP: he/she said NOT when it was actually LENS
# SWAP: their agent reckons their contribution (in bits) =  1.99471942959
# SWAP: while estimating their PL,PD as  0.152173913043 0.933333333333
# SWAP: and the subject's new probability as  0.000159955385968

# NB information is wrong...
# If accuracy is missing, then we get a bunch of people just saying 
# no to everything! And then subjects just fall straight. 


# Try initialNL = 5 or so to allow for mistakes early on, and compare
# use_marker_positions = True and False, on the first 300k.

time SWAPSHOP.csh -s CFHTLS-strict-NO-useXY -f --fast -t 6

# and then: 

time SWAPSHOP.csh -s CFHTLS-strict-YES-useXY -f --fast -t 6

# OK! Compare numbers:

# Very similar, but:
# 
# Quantity        NO     YES
# Retirements    3000    150 
# Missed lenses   13%     9%

# ie the bureau is more circumspect. And much slower to retire!

# DECISION: use XY, but investigate skepticism. These results used
# skepticism = 3! Also, need more data. Run on all of 2010-05-10.

# Now, vary agent skepticism (initialNL,ND = 2 + skepticism).
# Also, bump up detection threshold to 0.95!

time SWAPSHOP.csh -s CFHTLS-skeptic00 -f --fast

time SWAPSHOP.csh -s CFHTLS-skeptic03 -f --fast

time SWAPSHOP.csh -s CFHTLS-skeptic08 -f --fast

# Skepticism              0        3        8 
# Retirements         28489    25574    21271
# Age at retirement    15.6     17.8     20.3
# Missed lenses        18.5%    18.3%    18.1%
# Candidates            148       64       21

# Looks like skepticism slows things down without affecting false -ve 
# rate very much. I think we should go with skepticism = 0.
 
# Using 15 classifications per retirement is expensive.
# 400,000 * 15 = 6 million classifications!
# Maybe not that many: 375 each from 16,000 people

# Trajectories are roughly horizontal by the time we get close to 
# threshold - good, there is an end in sight! 


# What if using marker positions is causing a high false negative rate
# somehow? By giving people low PL values, so that they are disbelieved?
# Try skeptic00 with marker positions turned off.
 
time SWAPSHOP.csh -s CFHTLS-skeptic00-noXY -f --fast

# BTW each full run (10^6 classifications) takes about 14 mins.

# Use XY positions?     Yes       No
# Retirements         28489    35835
# Age at retirement    15.6     10.7
# Missed lenses        18.5%    20.1%
# Candidates            148      159

# So XY gives a *better* false neg rate! Good. 

# So, what about a training period? Level 1 has 20 subjects, 1 in 5 sims
# and 1 in 5 duds, so 8 training images total. Try ignoring all of level
# 1 and see what we get compared to the standard setup.

time SWAPSHOP.csh -s CFHTLS-skeptic00-ignore8 -f --fast -t 20

# (Note that I SWIPED the new db in the meantime - oops)

# Run:                skeptic00      ignore8
# Classifications        666864       536099
# Retirements             28489        27346
# Age at retirement        15.6         12.8
# Missed lenses            18.5%        16.3%
# Candidates                148          146

# So its cleaner and cheaper. I think we have to do this. Make it 
# past level 2 and your classifications start to count! Rough
# qualification is 20 classifications - we asked for 40 in the PR. 
# We can always go back later and make more use of the ignored clicks,
# with a better model for how the agents learn. 

# OK, done! Retirement plan is skeptic00, defined by this config:
# 
# skepticism: 0
#
# a_few_at_the_start: 8
# 
# use_marker_positions: True
# 
# detection_threshold: 0.95
# 
# rejection_threshold: 1e-7
# 
# Checked in as startup.config! Done.

# ======================================================================
# 2013-05-11 (Saturday) 19:52 BST

# Restore latest db to start production run. Run SWAPSHOP in production 
# directory so that we can re-use the pickles.

mkdir -p $SWAP_DIR/analysis/production
chdir $SWAP_DIR/analysis/production

SWIPE.csh spacewarp_2013-05-11.gz

# OK, now SWAPSHOP with simple survey name. No need for -f once we are 
# rolling!

SWAPSHOP.csh -s CFHTLS -f --fast

# OK good - we are rolling!

# ======================================================================
# 2013-05-12 (Sunday) 19:57 CEST

# Right, more retirements! 

SWIPE.csh spacewarp_2013-05-12.gz

SWAPSHOP.csh -s CFHTLS --fast

# Had to do retirments by hand, as script got it wrong to start with. 
# Here's how I recovered:

wc -l */*retire*
#    33648 CFHTLS_2013-05-11_10:04:13/CFHTLS_2013-05-11_10:04:13_retire_these.txt
#    36706 CFHTLS_2013-05-12_10:05:01/CFHTLS_2013-05-12_10:05:01_retire_these.txt

set survey = CFHTLS
\set latest = `\ls -dtr ${survey}_????-??-??_??:??:?? | tail -1`

set previousretirees = CFHTLS_previously_retired.txt
cat $previousretirees         | sort > old
cat $latest/*retire_these.txt | sort > new
sdiff -s old new | & cut -d'>' -f2 > diff
wc -l old new diff
#    33648 old
#    36706 new
#     3058 diff
mv diff CFHTLS_production_retire_these.txt

# Good! Retire these:

SWITCH.py CFHTLS_production_retire_these.txt

# ================================================================================
#                    SWITCH: the Space Warps Retirement Plan                      
# ================================================================================
# SWITCH: retiring subjects listed in  CFHTLS_production_retire_these.txt
# SWITCH: looks like we have 3058  subjects to retire
# SWITCH: successfully retired subject ASW0000008
# SWITCH: successfully retired subject ASW000000t
# SWITCH: successfully retired subject ASW0000016
# SWITCH: successfully retired subject ASW000001h
# SWITCH: successfully retired subject ASW000001i
# SWITCH: successfully retired subject ASW000001k
# SWITCH: successfully retired subject ASW000001o

# etc . Success! 

# Well, partially. Got back fom dinner to find:

# SWITCH: retirement fail:  ASW0000chb False
# failed: unauthorized, check your credentials(0)

# for a whole bunch of subjects. Emailed Parrish for advice.

# ======================================================================
# 2013-05-14 (Tuesday) 00:54 CEST

# OK, I hit the retirements per hour limit. Michael put it up to 5000
# That means we can do 1 retirment every 0.72 secs. Add sleep 0.7 to 
# code, and run overnight! We probably only did 3000 yesterday before it
# got locked out, so might as well start from teh beginning gain.

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Great, now they are all done!

# ======================================================================
# 2013-05-15 (Wednesday) 00:38 CEST

# Catching up - need to do both 13 and 14 May dumps.

SWIPE.csh spacewarp_2013-05-13.gz
SWAPSHOP.csh -s CFHTLS --fast

# Got 7463 subjects to retire - do in 3 batches:

head -2500 CFHTLS_production_retire_these.txt > batch1.txt
head -5000 CFHTLS_production_retire_these.txt | tail -2500 > batch2.txt
tail -2463 CFHTLS_production_retire_these.txt > batch3.txt

SWITCH.py batch1.txt > retirement1.log &

# Do the following next!! 2013-05-15 (Wednesday) 09:36 CEST

SWITCH.py batch2.txt > retirement2.log &
SWITCH.py batch3.txt > retirement3.log &

# Phew - just finished. That was an effort. 2013-05-17 (Friday) 01:04 CEST

# Tomorrow, need to process 2013-05-14, 15, 16... Starting with SWIPE.

# ======================================================================
# 2013-05-17 (Friday) 18:51 CEST

# On plane home from Copenhagen. Catch up!
# Need to deal with interrupted retirements in SWITCH.

# First, run SWAPSHOP on latest db! Make plots later...

SWIPE.csh spacewarp_2013-05-17.gz
SWAPSHOP.csh -s CFHTLS --fast

# SWAP: report compiled as /Users/pjm/public_html/SpaceWarps/Science/analysis/production/CFHTLS_2013-05-17_10:07:53/CFHTLS_2013-05-17_10:07:53_report.pdf
# ================================================================================
# SWAPSHOP: if you want, you can go ahead and retire 40595 subjects with
#  
#           SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Report shows 84130 subjects, 63722 to be retired. 
# Numbers don't add up! Check lists:

sort -n CFHTLS_previously_retired.txt | uniq | sed s/' '//g | grep 'ASW' > old
sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new

tabs2spaces -n 0 old new

wc -l CFHTLS_previously_retired.txt old CFHTLS_production_retire_these.txt new
#    44169 CFHTLS_previously_retired.txt
#    44169 old
#    40595 CFHTLS_production_retire_these.txt
#    33132 new

# Retirement list has some repeats in it!
# Also, sdiff does not work for finding difference between files.
# Brute force it! First, update these files.

mv new CFHTLS_production_retire_these.txt
rm old

\rm junk
foreach ID ( `cat CFHTLS_production_retire_these.txt` )
  set done = `grep $ID CFHTLS_previously_retired.txt | wc -l`
  if (! $done) echo $ID >> junk
end  
wc -l junk
#   25669 junk   

# OK, 44169 old + 25669 new = 69838
# Why is this different from the 63722 listed?
# Did many of the old ones not actually get retired?
# Safe thing to do is retire eveything in 
# CFHTLS_production_retire_these.txt - won't make any difference to 
# re-retire things, it just takes longer. Run overnight!

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &


# ======================================================================
# 2013-05-19 (Sunday) 09:35 BST

# Run SWAPSHOP on latest db. Hopefully retirements are now cleaned up 
# following yesterday's run:

SWIPE.csh spacewarp_2013-05-18.gz
SWAPSHOP.csh -s CFHTLS --fast

# SWAPSHOP: if you want, you can go ahead and retire 15228 subjects with
#  
#           SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &
 
# Hmm - still not counting right?

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#     7765 new

# Hmm. Need to fix this. Over-write for now!

mv new CFHTLS_production_retire_these.txt

# Pausing retirment plan while we wait for Michael...

# 2013-05-20 (Monday) 23:03 BST
# OK got green light!

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# OK good! Onto May 20.
# 2013-05-21 (Tuesday) 10:54 BST

SWIPE.csh spacewarp_2013-05-21.gz
SWAPSHOP.csh -s CFHTLS --fast

# Wow - 32517 retirements?!

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new

# OK, "only" 17289 really...

mv new CFHTLS_production_retire_these.txt

# Retire them!

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# ======================================================================
# 2013-05-22 (Wednesday) 13:24 BST

SWIPE.csh spacewarp_2013-05-22.gz
SWAPSHOP.csh -s CFHTLS --fast
sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#   19193 new
mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# ======================================================================
# 2013-05-23 (Thursday) 12:45 BST

SWIPE.csh spacewarp_2013-05-23.gz
SWAPSHOP.csh -s CFHTLS --fast
sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#   23533 new
mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# ======================================================================
# 2013-05-24 (Friday) 12:17 BST

SWIPE.csh spacewarp_2013-05-24.gz
SWAPSHOP.csh -s CFHTLS --fast
sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#   
mv new CFHTLS_production_retire_these.txt

# Try retiring from SLAC: Fail! No requests module. Ho hum.

nohup SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# ======================================================================
# 2013-05-26 (Sunday) 21:00 BST

SWIPE.csh spacewarp_2013-05-26.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#   44392 new
mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# ======================================================================
# 2013-05-27 (Monday) 17:44 BST

SWIPE.csh spacewarp_2013-05-27.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#   49761 new
mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Wow - that won't leave many...

# ======================================================================
# 2013-05-26 (Sunday) 21:00 BST

SWIPE.csh spacewarp_2013-05-28.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#    54393 new  
mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Need to get D6 in? Wait for a bit.

# ======================================================================
# 2013-05-30 (Thursday) 09:59 BST

SWIPE.csh spacewarp_2013-05-29.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#  58484 new  
mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Retire these duds!

# Ran out of time - had to abort:
wc -l retirement.log
#   28238 retirement.log

# Restart on Friday night from New York!

# ======================================================================
# 2013-05-31 (Friday) 23:50 EDT

SWIPE.csh spacewarp_2013-05-31.gz
SWAPSHOP.csh -s CFHTLS --fast

# SWAP: interpreting up to 50000  classifications...
# ERROR: AttributeError: 'NoneType' object has no attribute 'has_key' [swap.mongodb]
# Traceback (most recent call last):
#   File "/Users/pjm/public_html/SpaceWarps/Science/analysis/SWAP.py", line 422, in <module>
#     SWAP(sys.argv[1:])
#   File "/Users/pjm/public_html/SpaceWarps/Science/analysis/SWAP.py", line 203, in SWAP
#     items = db.digest(classification,method=use_marker_positions)
#   File "/Users/pjm/public_html/SpaceWarps/Science/analysis/swap/mongodb.py", line 154, in digest
#     if subject.has_key('group_id'):
# AttributeError: 'NoneType' object has no attribute 'has_key'
# SWAPSHOP: if you want, you can go ahead and retire 140567 subjects with
#  
#           SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Hmm - wonder what that problem is?

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#    58484 new  
mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Off we go again! Run overnight.

# ======================================================================
# 2013-06-01 (Saturday) 22:18 EDT

SWIPE.csh spacewarp_2013-06-01.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#   73358 new 
mv new CFHTLS_production_retire_these.txt

# Seems very high! Are retirement requests not working?
# Compare log with new list:

set count = 0
\rm -f new
foreach subject ( `cat CFHTLS_production_retire_these.txt` )
   set k = `grep $subject retirement.log | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k > 1) then
       echo "Whoah! $subject was retired $k times yesterday!"
   else if ($k == 0) then
       echo $subject >> new
   endif
end
echo "$count subjects scheduled for re-retirement, can be ignored"
echo "List of subjects to be retired afresh:"
wc -l new

# 58484 subjects scheduled for re-retirement, can be ignored
# List of subjects to be retired afresh:
#   14874 new

mv new CFHTLS_production_retire_these.txt

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-03 (Monday) 08:16 EDT

SWIPE.csh spacewarp_2013-06-03.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#   65263 new 
mv new CFHTLS_production_retire_these.txt

# Seems very high! Are retirement requests not working?
# Compare log with new list:

set count = 0
\rm -f new
foreach subject ( `cat CFHTLS_production_retire_these.txt` )
   set k = `grep $subject retirement.log | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k > 1) then
       echo "Whoah! $subject was retired $k times yesterday!"
   else if ($k == 0) then
       echo $subject >> new
   endif
end
echo "$count subjects scheduled for re-retirement, can be ignored"
echo "List of subjects to be retired afresh:"
wc -l new

# 0 subjects scheduled for re-retirement, can be ignored
# List of subjects to be retired afresh:
# wc -l new
#    65263 new

# Wow. 
# OK, better get started! :-)

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Stop part way through:

grep -n ASW0001jfc CFHTLS_production_retire_these.txt 
# 12195:
tail -n +12196 CFHTLS_production_retire_these.txt > \
               CFHTLS_production_now_retire_these.txt

SWITCH.py CFHTLS_production_now_retire_these.txt >> retirement.log &

# And again!

grep -n ASW000261b CFHTLS_production_retire_these.txt 
# 30106:
tail -n +30107 CFHTLS_production_retire_these.txt > \
               CFHTLS_production_and_now_retire_these.txt

SWITCH.py CFHTLS_production_and_now_retire_these.txt >> retirement.log &

# And again...

grep -n ASW0002lsr CFHTLS_production_retire_these.txt 
# 45799:
tail -n +45800 CFHTLS_production_retire_these.txt > \
               CFHTLS_production_and_NOW_retire_these.txt

SWITCH.py CFHTLS_production_and_NOW_retire_these.txt >> retirement.log &


# ======================================================================
# 2013-06-05 (Wednesday) 07:45 EDT

SWIPE.csh spacewarp_2013-06-05.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
#  72222 new
mv new CFHTLS_production_retire_these.txt

set count = 0
\rm -f new
foreach subject ( `cat CFHTLS_production_retire_these.txt` )
   set k = `grep $subject retirement.log | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k > 1) then
       echo "Whoah! $subject was retired $k times yesterday!"
   else if ($k == 0) then
       echo $subject >> new
   endif
end
echo "$count subjects scheduled for re-retirement, can be ignored"
echo "List of subjects to be retired afresh:"
wc -l new

# 65260 subjects scheduled for re-retirement, can be ignored
# List of subjects to be retired afresh:
#     6959 new

mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Got a bunch of these:
# 
# HTTPSConnectionPool(host='api.zooniverse.org', port=443): Max retries exceeded with url: /admin/login (Caused by <class 'socket.error'>: [Errno 50] Network is down)(1)

# Killed process. Restart:

grep ASW retirement.log | grep -v fail | grep -v error | tail -1
# SWITCH: successfully retired subject ASW0004weo
grep -n ASW0004weo CFHTLS_production_retire_these.txt 
# 5904:ASW0004weo
tail -n +5905 CFHTLS_production_retire_these.txt > \
              CFHTLS_production_now_retire_these.txt

SWITCH.py CFHTLS_production_now_retire_these.txt >> retirement.log &

# ======================================================================
# 2013-06-06 (Thursday) 23:01 CDT

SWIPE.csh spacewarp_2013-06-06.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
# 70950  Pretty sure these are not all new but retire them anyway...
mv new CFHTLS_production_retire_these.txt
SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# Killed job in order to start fresh on Sunday!

grep uccess retirement.log | wc -l
#    58595
# ======================================================================
# 2013-06-09 (Sunday) 09:46 PDT

SWIPE.csh spacewarp_2013-06-09.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
# 84664 new
mv new CFHTLS_production_retire_these.txt

# OK, these have to be repeats. Compare with yesterday's retiremnets.

set count = 0
\rm -f new
foreach subject ( `cat CFHTLS_production_retire_these.txt` )
   set k = `grep $subject retirement.log | grep uccess | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k > 1) then
       echo "Whoah! $subject was retired $k times yesterday!"
   else if ($k == 0) then
       echo $subject >> new
   endif
end
echo "$count subjects scheduled for re-retirement, can be ignored" ; \
echo "List of subjects to be retired afresh:" ; \
wc -l new

# 58593 subjects scheduled for re-retirement, can be ignored
# List of subjects to be retired afresh:
#   26071 new

# OK, that's plausible! Off we go then:
mv new CFHTLS_production_retire_these.txt

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# All done!

# ======================================================================
# 2013-06-10 (Monday) 08:07 PDT

SWIPE.csh spacewarp_2013-06-10.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
# 64721 new
mv new CFHTLS_production_retire_these.txt

set count = 0
\rm -f new
foreach subject ( `cat CFHTLS_production_retire_these.txt` )
   set k = `grep $subject retirement.log | grep uccess | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k > 1) then
       echo "Whoah! $subject was retired $k times yesterday!"
   else if ($k == 0) then
       echo $subject >> new
   endif
end
echo "$count subjects scheduled for re-retirement, can be ignored" ; \
echo "List of subjects to be retired afresh:" ; \
wc -l new

# 3058 subjects scheduled for re-retirement, can be ignored
# List of subjects to be retired afresh:
#    61663 new

mv new CFHTLS_production_retire_these.txt

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# 66072 retirement.log

# ======================================================================
# 2013-06-12 (Wednesday) 14:43 PDT

SWIPE.csh spacewarp_2013-06-12.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
# 10390 new
mv new CFHTLS_production_retire_these.txt

SWITCH.py CFHTLS_production_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-13 (Thursday) 08:35 PDT

# Today we compare simple and fuzzy trajectories! First do simple run,
# as control:

SWIPE.csh spacewarp_2013-06-13.gz
SWAPSHOP.csh -s CFHTLS --fast

sort -n CFHTLS_production_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
# 13908 new
mv new CFHTLS_production_retire_these.txt

set count = 0
\rm -f new
foreach subject ( `cat CFHTLS_production_retire_these.txt` )
   set k = `grep $subject retirement.log | grep uccess | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k > 1) then
       echo "Whoah! $subject was retired $k times yesterday!"
   else if ($k == 0) then
       echo $subject >> new
   endif
end
echo "$count subjects scheduled for re-retirement, can be ignored" ; \
echo "List of subjects to be retired afresh:" ; \
wc -l new

# 10390 subjects scheduled for re-retirement, can be ignored
# List of subjects to be retired afresh:
#     3518 new
mv new CFHTLS_production_retire_these.txt

# OK, don't retire these - let's now compare with the fuzzies! 
# First need to accept Surhud's pull request, then check out the code
# into the Space Warps directory. If I decide to go back, I can just
# check out the previous version of SWAP... but Ill need a separate 
# workspace, at the same level as "production". Call it: fuzzy.

# Need to get sartup.config right - check Surhud's emails.

# Here's the pull output:

# From github.com:drphilmarshall/SpaceWarps
#    d43ef4b..d77816a  master     -> origin/master
# Updating d43ef4b..d77816a
# Fast-forward
#  analysis/SWAP.py                |    6 ++
#  analysis/SWAPSHOP.csh           |    3 +
#  analysis/swap/agent.py          |   30 ++++++++
#  analysis/swap/bureau.py         |    8 +++
#  analysis/swap/collection.py     |   31 +++++---
#  analysis/swap/config.py         |    1 +
#  analysis/swap/logging.py        |   18 +++--
#  analysis/swap/production.config |    8 +--
#  analysis/swap/startup.config    |    6 +-
#  analysis/swap/subject.py        |   65 ++++++++++++-----
#  doc/sw-system.tex               |  151 ++++++++++++++++++---------------------
#  11 files changed, 204 insertions(+), 123 deletions(-)

# Forgot to tag it before pulling, oops. Ah well! Onwards :-)

SWAPSHOP.csh -s CFHTLS --fast --startup

# startup option brings over startup.config etc. Ntrajectory is set in 
# the header of subject.py, which is a bug... But its set to 50
# as recommenedded by Surhud.

# Timing runs: each iteration of 50,000 classifications takes about a
# minute, a little over. With 5 million classifications, the whole 
# SWAPSHOP run will take at least 100 mins - say 2 hours.

# Then, compare reports, and also lists of retirees. This needs to be
# done carefully, using grep and awk etc, not sdiff, probably. 

# had to pause after 139 iterations - and it didn not restart cleanly
# :-(

SWAPSHOP.csh -s CFHTLS --fast

# OK, compare reports and retirements. Not easy, as we have to
# accumulate them uniquely. First clean up the fuzzy retirements!

sort -n CFHTLS_fuzzy_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
# 176818 new  GOOD!
mv new CFHTLS_fuzzy_retire_these.txt

mkdir -p comparison
cp CFHTLS_fuzzy_retire_these.txt CFHTLS_fuzzy_report.pdf comparison/

# OK, now bring in all retirements done so far from production...

cp ../production/CFHTLS_previously_retired.txt \
        comparison/CFHTLS_production_previously_retired.txt
cp ../production/CFHTLS_production_retire_these.txt comparison/

# Hmm - previous retirements will have doubles in them from repeated 
# days efforts:

cd comparison

cat CFHTLS_production_previously_retired.txt | awk '{print $1}' | \
  grep 'ASW' | sort -n | uniq > new
wc -l CFHTLS_production_previously_retired.txt new
#   275170 CFHTLS_production_previously_retired.txt
#   177563 new
# OK, potentially very similar! Let's see.
mv new CFHTLS_production_previously_retired.txt

# Just to make sure, do same thing to the fuzzies:
cat CFHTLS_fuzzy_retire_these.txt | awk '{print $1}' | \
  grep 'ASW' | sort -n | uniq > new
wc -l CFHTLS_fuzzy_retire_these.txt new
#   176818 CFHTLS_fuzzy_retire_these.txt
#   176818 new
mv new CFHTLS_fuzzy_retire_these.txt

# Good. Now, we need two lists: 
# 1) Subjects to retire now
# 2) Subjects to resurrect now

# 1) Take the fuzzy retirement list, and remove all that appear in
#    either the production previous retirements, or the production
#    retire these list.

cat CFHTLS_production_previously_retired.txt \
    CFHTLS_production_retire_these.txt | \
  awk '{print $1}' | grep 'ASW' | sort -n | uniq \
  > CFHTLS_production_all_retirements.txt
  
set retirements = CFHTLS_to_turn_fuzzy_retire_these.txt
set count = 0
\rm -f $retirements
foreach subject ( `cat CFHTLS_fuzzy_retire_these.txt` )
   set k = `grep $subject CFHTLS_production_all_retirements.txt | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k == 0) then
       echo $subject >> $retirements
   endif
end
echo "$count subjects already happily retired, can be ignored" ; \
echo "List of subjects to be retired:" ; \
wc -l $retirements

# 176463 subjects already happily retired, can be ignored
# List of subjects to be retired:
#      355 CFHTLS_to_turn_fuzzy_retire_these.txt

# Cool!


# 2) Take the production previously retired list, and remove the 
#    subjects that appear in the fuzzy retirement list.

set resurrections = CFHTLS_to_turn_fuzzy_resurrect_these.txt
set count = 0
\rm -f $resurrections
foreach subject ( `cat CFHTLS_production_previously_retired.txt` )
   set k = `grep $subject CFHTLS_fuzzy_retire_these.txt | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k == 0) then
       echo $subject >> $resurrections
   endif
end
echo "$count subjects already happily retired, can be ignored" ; \
echo "List of subjects to be resurrected:" ; \
wc -l $resurrections

# 173060 subjects already happily retired, can be ignored
# List of subjects to be resurrected:
#     4503 CFHTLS_to_turn_fuzzy_resurrect_these.txt

# OK, execute this, then continue running SWITCH in fuzzy directory
# tomorrow? Yes - state is read from pickles, not from mongodb.

SWITCH.py CFHTLS_to_turn_fuzzy_retire_these.txt > turning_fuzzy_retirement.log &

SWITCH.py -r CFHTLS_to_turn_fuzzy_resurrect_these.txt > turning_fuzzy_resurrection.log &

# OK, done! Now, to start SWAPPING from directory fuzzy.

# ======================================================================
# 2013-06-15 (Saturday) 09:44 PDT

cd fuzzy

SWIPE.csh spacewarp_2013-06-15.gz
SWAPSHOP.csh -s CFHTLS --fast

# Had to restart after trashing production mongo directory and re-SWIPEing.

# SWAPSHOP: if you want, you can go ahead and retire 184711 subjects with
#  
#           SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# Hmm. Seems like a lot! As if it didn't know what had been retired...
# Need to compare with log somehow.

sort -n CFHTLS_fuzzy_retire_these.txt | uniq | sed s/' '//g | grep 'ASW' > new
wc -l new
# 184711 new
mv new CFHTLS_fuzzy_retire_these.txt

# OK, try faking a retirement log!

cat comparison/CFHTLS_fuzzy_retire_these.txt > retirement.txt

# Now do the line by line comparison:

set count = 0
\rm -f new
foreach subject ( `cat CFHTLS_fuzzy_retire_these.txt` )
   set k = `grep $subject retirement.txt | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k == 0) then
       echo $subject >> new
   endif
end
echo "$count subjects scheduled for re-retirement, can be ignored" ; \
echo "List of subjects to be retired afresh:" ; \
wc -l new
# 176818 subjects scheduled for re-retirement, can be ignored
# List of subjects to be retired afresh:
#     7893 new

# Over-write with new file:
mv new CFHTLS_fuzzy_retire_these.txt

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# OK done - we are up and running.

# ======================================================================
# 2013-06-17 (Monday) 08:34 PDT

SWIPE.csh spacewarp_2013-06-17.gz

# Sort out these retirement lists. SWAPSHOP will concatenate
# previously_retired and the current copy of retire_these before
# over-writing - so we have to set up the former accordingly.

mv comparison/CFHTLS_fuzzy_retire_these.txt \
              CFHTLS_previously_retired.txt

SWAPSHOP.csh -s CFHTLS --fast

# SWAPSHOP: so far we have retired 184711 subjects. Let's do some more!
#   Good :-)
# ...
# SWAPSHOP: previous run brought total retirements to:
#   184711 CFHTLS_previously_retired.txt
# SWAPSHOP: current run has suggested another batch:
#   194387 CFHTLS_fuzzy_retire_these.txt
# SWAPSHOP: after filtering for repeats, the new retirements number:
#   194387 CFHTLS_fuzzy_retire_these.txt
# SWAPSHOP: after checking for uniqness, we need to retire these:
#     9676 CFHTLS_fuzzy_retire_these.txt
# SWAPSHOP: 184711 subjects were already retired and can be ignored

# OK, let's go!

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# Got interrupted, sigh.


# ======================================================================
# 2013-06-18 (Tuesday) 17:43 PDT

SWIPE.csh spacewarp_2013-06-18.gz

SWAPSHOP.csh -s CFHTLS --fast

# SWAPSHOP: 176772 subjects were already retired and can be ignored
# SWAPSHOP: if you want, you can go ahead and retire 4340 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &
 
# ======================================================================
# 2013-06-19 (Wednesday) 11:22 PDT

SWIPE.csh spacewarp_2013-06-19.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: after checking for uniqness, we need to retire these:
#     3239 CFHTLS_fuzzy_retire_these.txt
# SWAPSHOP: 0 subjects were already retired and can be ignored
# SWAPSHOP: if you want, you can go ahead and retire 3239 subjects

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &
 
# ======================================================================
# 2013-06-20 (Thursday) 08:57 PDT

SWIPE.csh spacewarp_2013-06-20.gz

SWAPSHOP.csh -s CFHTLS --fast

# SWAPSHOP: after checking for uniqness, we need to retire these:
#     3448 CFHTLS_fuzzy_retire_these.txt

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &
SWITCH.py CFHTLS_fuzzy_now_retire_these.txt >> retirement.log &

# ======================================================================
# 2013-06-21 (Friday) 05:52 PDT

SWIPE.csh spacewarp_2013-06-21.gz

SWAPSHOP.csh -s CFHTLS --fast

# SWAPSHOP: so far we have retired 205414 subjects. Let's do some more!
# SWAPSHOP: after checking for uniqness, we need to retire these:
#     2910 CFHTLS_fuzzy_retire_these.txt

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-22 (Saturday) 11:37 PDT

SWIPE.csh spacewarp_2013-06-22.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-23 (Sunday) 21:28 PDT

SWIPE.csh spacewarp_2013-06-23.gz
# SWIPE: mongorestore log stored in .spacewarp_2013-06-23_mongorestore.log
# SWIPE: ERROR: failed to restore database, exiting

# Huh?
more .spacewarp_2013-06-23_mongorestore.log
# Mon Jun 24 06:12:42.314 kern.sched unavailable
# couldn't connect to [127.0.0.1] couldn't connect to server 127.0.0.1:27017

# Try again from SLAC.

# ======================================================================
# 2013-06-24 (Monday) 09:46 PDT

SWIPE.csh spacewarp_2013-06-24.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-26 (Wednesday) 14:02 PDT

SWIPE.csh spacewarp_2013-06-26.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 6120 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-27 (Thursday) 14:59 PDT

SWIPE.csh spacewarp_2013-06-27.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2004 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-28 (Friday) 12:00 PDT

SWIPE.csh spacewarp_2013-06-28.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2788 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-29 (Saturday) 07:46 PDT

SWIPE.csh spacewarp_2013-06-29.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-06-30 (Sunday) 12:29 PDT

sleep 500

SWIPE.csh spacewarp_2013-06-30.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-01 (Monday) 14:10 PDT

SWIPE.csh spacewarp_2013-07-01.gz

SWAPSHOP.csh -s CFHTLS --fast
#SWAPSHOP: if you want, you can go ahead and retire 2419 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-02 (Tuesday) 06:31 PDT

SWIPE.csh spacewarp_2013-07-02.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2005 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-03 (Wednesday) 08:09 PDT

SWIPE.csh spacewarp_2013-07-03.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1803 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-03 (Wednesday) 08:09 PDT

SWIPE.csh spacewarp_2013-07-04.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-05 (Friday) 14:39 PDT

SWIPE.csh spacewarp_2013-07-05.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-06 (Saturday) 09:49 PDT

SWIPE.csh spacewarp_2013-07-06.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-07 (Sunday) 15:46 PDT

SWIPE.csh spacewarp_2013-07-07.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1270 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-08 (Monday) 06:23 PDT

SWIPE.csh spacewarp_2013-07-08.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-09 (Tuesday) 17:08 PDT

SWIPE.csh spacewarp_2013-07-09.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 658 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-11 (Thursday) 08:18 PDT

SWIPE.csh spacewarp_2013-07-11.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1023 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-12 (Friday) 08:52 PDT

SWIPE.csh spacewarp_2013-07-12.gz

SWAPSHOP.csh -s CFHTLS --fast
#SWAPSHOP: if you want, you can go ahead and retire 394 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &


# OK, we have time to try a full run, with plots. How much space is needed?

# 135 epochs, each with a 6Mb plot: 800Mb. Available disk space?
# 8.3Gb. Let's do it! 

mkdirf fuzzy-with-plots
SWAPSHOP.csh -s CFHTLS --startup --animate

# Hmm - computer crashed, job stopped. Restart! Needs loaded Mongo, so wait
# until Sunday's production run is started!

SWAPSHOP.csh -s CFHTLS --animate

# ======================================================================
# 2013-07-14 (Sunday) 08:21 PDT

SWIPE.csh spacewarp_2013-07-14.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# Huh - no retirements! :-/

# ======================================================================
# 2013-07-15 (Monday) 10:58 PDT

SWIPE.csh spacewarp_2013-07-15.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 882 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# Hmm - maybe the other SWAP run interfered with things yesterday?

# ======================================================================
# 2013-07-16 (Tuesday) 08:35 PDT

SWIPE.csh spacewarp_2013-07-16.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-17 (Wednesday) 22:05 PDT

SWIPE.csh spacewarp_2013-07-17.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 130 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-18 (Thursday) 10:45 PDT

SWIPE.csh spacewarp_2013-07-18.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 168 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-19 (Friday) 10:17 PDT

SWIPE.csh spacewarp_2013-07-19.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 217 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-20 (Saturday) 21:28 PDT

SWIPE.csh spacewarp_2013-07-20.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 296 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-21 (Sunday) 08:24 PDT

SWIPE.csh spacewarp_2013-07-21.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-22 (Monday) 10:07 PDT

SWIPE.csh spacewarp_2013-07-22.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 554 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-24 (Wednesday) 08:43 PDT

SWIPE.csh spacewarp_2013-07-24.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2472 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-26 (Friday) 07:19 PDT

SWIPE.csh spacewarp_2013-07-26.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 3090 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-28 (Sunday) 10:29 PDT

SWIPE.csh spacewarp_2013-07-28.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 4330 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-29 (Monday) 12:32 PDT

SWIPE.csh spacewarp_2013-07-29.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1870 subjects with

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-07-30 (Tuesday) 08:29 PDT

SWIPE.csh spacewarp_2013-07-30.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_fuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-08-04 (Sunday) 17:27 PDT

SWIPE.csh spacewarp_2013-08-04.gz

SWAPSHOP.csh -s CFHTLS --fast

# SWAPSHOP: previous run brought total retirements to:
#   262756 CFHTLS_previously_retired.txt
# SWAPSHOP: current run has suggested another batch:
#   260243 CFHTLS_fuzzy_retire_these.txt
# SWAPSHOP: after checking for uniqness, we need to retire these:
#        0 CFHTLS_fuzzy_retire_these.txt
# SWAPSHOP: 260243 subjects were already retired and can be ignored
# SWAPSHOP: no subjects to retire

# Eh? Something odd happened here. Check retirement list:

wc -l CFHTLS_2013-0*/*retire_these.txt | tail
#   247869 CFHTLS_2013-07-20_10:10:07/CFHTLS_2013-07-20_10:10:07_retire_these.txt
#   248423 CFHTLS_2013-07-21_10:10:17/CFHTLS_2013-07-21_10:10:17_retire_these.txt
#   249244 CFHTLS_2013-07-22_10:12:05/CFHTLS_2013-07-22_10:12:05_retire_these.txt
#   251716 CFHTLS_2013-07-24_10:12:14/CFHTLS_2013-07-24_10:12:14_retire_these.txt
#   254806 CFHTLS_2013-07-26_10:08:30/CFHTLS_2013-07-26_10:08:30_retire_these.txt
#   259136 CFHTLS_2013-07-28_10:13:09/CFHTLS_2013-07-28_10:13:09_retire_these.txt
#   261006 CFHTLS_2013-07-29_10:14:18/CFHTLS_2013-07-29_10:14:18_retire_these.txt
#   262756 CFHTLS_2013-07-30_10:12:24/CFHTLS_2013-07-30_10:12:24_retire_these.txt
#     2513 CFHTLS_2013-08-04_10:26:49/CFHTLS_2013-08-04_10:26:49_retire_these.txt

# Why is August 4th's so short? OK, here's the problem:

# SWAPSHOP: so far we have retired 262756 subjects. Let's do some more!
# SWAPSHOP: starting batch number 1
# ================================================================================
#                    SWAP: the Space Warps Analysis Pipeline                      
# ================================================================================
# SWAP: updating all subjects with classifications made since 2013-07-30_10:12:24
# SWAP: read an old bureau of 31351 classification agents from ./CFHTLS_bureau.pickle
# SWAP: read an old collection of 296599 subjects from ./CFHTLS_collection.pickle
# SWAP: interpreting up to 50000  classifications...
# SWAP: .........................................................................
# SWAP: total no. of classifications processed:  50000
# SWAP: saving agents to ./CFHTLS_bureau.pickle
# SWAP: saving subjects to ./CFHTLS_collection.pickle
# ERROR: IOError: [Errno 28] No space left on device [swap.io]

# Damn - so new pickle was started in the next batch :-(

# Only solution is to re-run from scratch! And then manually compare the
# retirement list generated with the one currently marked as "previously
# retired". Do this in a new directory: newfuzzy

# ======================================================================
# 2013-08-05 (Monday) 09:13 PDT

# Note to self: when re-activating at Stage 2, do not do ASW000000001 through
# f - these have problematic labels, and in any case reappear in D11 without 
# sims in them.

# ======================================================================
# 2013-08-05 (Monday) 09:15 PDT

# Restarting from scratch! Do it fast though, no need for more plots.
# Also, implement hasty=False in config, to run using all classifications, 
# even on subjects that should have been retired. This way we will use 
# all classifications! :-) Report should show all classifications used.

# BTW, need to kill old mongo dir.

mkdirf $SWAP_DIR/allfuzzy
# /Users/pjm/public_html/SpaceWarps/Science/analysis/allfuzzy

SWIPE.csh spacewarp_2013-08-05.gz

# Copy old fuzzy retirees to here, so that the comparison can be done by 
# SWAPSHOP:

cp ../fuzzy/CFHTLS_previously_retired.txt .
cp ../fuzzy/CFHTLS_fuzzy_retire_these.txt .

# (The second file is empty.)

# Now the analysis:

SWAPSHOP.csh -s CFHTLS --fast --startup

# SWAPSHOP: start-up configuration stored in startup.config
# SWAPSHOP: so far we have retired 262756 subjects. Let's do some more!
# ...
# SWAPSHOP: previous run brought total retirements to:
#   262756 CFHTLS_previously_retired.txt
# SWAPSHOP: current run has suggested another batch:
#    18003 CFHTLS_allfuzzy_retire_these.txt
# SWAPSHOP: after checking for uniqness, we need to retire these:
#     9352 CFHTLS_allfuzzy_retire_these.txt
# SWAPSHOP: 8651 subjects were already retired and can be ignored
# SWAPSHOP: if you want, you can go ahead and retire 9352 subjects with
 

# Now compare this retirement list with the old fuzzy one:

# wc -l CFHTLS_*/*retire*
#   263457 CFHTLS_2013-08-05_10:14:39/CFHTLS_2013-08-05_10:14:39_retire_these.txt

# Retirements required are in 
wc -l CFHTLS_allfuzzy_retire_these.txt
#    9352 CFHTLS_allfuzzy_retire_these.txt

# Are there any resurrections needed? These are the subjects that are in the 
# old fuzzy retirement list, but not in the new one.

wc -l ../fuzzy/CFHTLS_previously_retired.txt 
#   262756 ../fuzzy/CFHTLS_previously_retired.txt
cp ../fuzzy/CFHTLS_previously_retired.txt CFHTLS_fuzzy_previously_retired.txt

# Difference is echo "263457 - 262756" | bc = 701

# Why is this different from the new number of retirements? 
#  -> Some of the previously retired systems need resurrecting.

# We might expect to have to resurrect 
# (9352-701 = 8651) systems. Need to make this resurrection list.

# From above: 
#  Take the previously retired list, and remove the 
#  subjects that appear in the fuzzy retirement list.
# The leftovers are to be resurrected!

set resurrections = CFHTLS_allfuzzy_resurrect_these.txt
set allfuzzyretirements = CFHTLS_2013-08-05_10:14:39/CFHTLS_2013-08-05_10:14:39_retire_these.txt
set fuzzyretirements = CFHTLS_fuzzy_previously_retired.txt
set newretirements = CFHTLS_allfuzzy_retire_these.txt

set count = 0
\rm -f $resurrections
foreach subject ( `cat $fuzzyretirements` )
   set k = `grep $subject $allfuzzyretirements | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k == 0) then
       echo $subject >> $resurrections
   endif
end
echo "$count subjects already happily retired, can be ignored" ; \
echo "List of subjects to be resurrected:" ; \
wc -l $resurrections

# 253852 subjects already happily retired, can be ignored
# List of subjects to be resurrected:
#     8904 CFHTLS_allfuzzy_resurrect_these.txt

# Some mismatch: this is not the expected 8651.
#  - could some resurrections be in NEW retirement list?

set count = 0
foreach subject ( `cat $newretirements` )
   set k = `grep $subject $resurrections | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   endif
end
echo "$count new retirements will have just been resurrected!"

# 0 new retirements will have just been resurrected!
# Hmm. 

# Oh well. Do 8904 resurrections, then 9532 retirements, then 
# start afresh tomorrow using the allfuzzy pickles.

SWITCH.py -r CFHTLS_allfuzzy_resurrect_these.txt >& CFHTLS_allfuzzy_resurrect_these.log 

# List includes 14 at the beginning that are not to be resurrected - but
# script takes care of them.

SWITCH.py CFHTLS_allfuzzy_retire_these.txt >& CFHTLS_allfuzzy_retire_these.log

# OK, now need to make the correct previously retired list, for SWAPSHOP:

cp $allfuzzyretirements CFHTLS_allfuzzy_previously_retired.txt

# OK, SWAPSHOP will concatenate this with CFHTLS_allfuzzy_retire_these.txt
# the next time the script runs.



# Check stats on report!

cp CFHTLS_2013-08-05_10:14:39/CFHTLS_2013-08-05_10:14:39_report.pdf \
   CFHTLS_allfuzzy_2013-08-05_10:14:39_report.pdf

# False negative rate is down to 2.9%
# Lens completeness is 93.5%
# Lens purity is 2.1% (1708 candidates)
# Mean classifications per subject: 23.3 

# Compare with most recent meaningful fuzzy report:

cp ../fuzzy/CFHTLS_2013-07-30_10:12:24/CFHTLS_2013-07-30_10:12:24_report.pdf \
   CFHTLS_fuzzy_2013-07-30_10:12:24_report.pdf

# FN: 7.1%
# C:  92.2%
# P:  0.1% (2153 candidates)
# Nc: 8.0

# GREAT. However, these numbers depend on the sims, which are classified 
# hundreds of times each: so they may well not be accurate :-/ Not sure what
# to do about this. Previous system (hasty: True) had systems ignored,
# and then retired, as soon as they crossed threshold - the same wa strue for
# the sims. Return to this mode later?

# ======================================================================
# 2013-07-30 (Tuesday) 08:29 PDT

SWIPE.csh spacewarp_2013-08-07.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: previous run brought total retirements to:
#   263457 CFHTLS_allfuzzy_previously_retired.txt
# SWAPSHOP: current run has suggested another batch:
#     4411 CFHTLS_allfuzzy_retire_these.txt
# SWAPSHOP: after checking for uniqness, we need to retire these:
#     3853 CFHTLS_allfuzzy_retire_these.txt
# SWAPSHOP: 558 subjects were already retired and can be ignored
# SWAPSHOP: if you want, you can go ahead and retire 3853 subjects with
 
SWITCH.py CFHTLS_allfuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-08-08 (Thursday) 13:36 PDT

SWIPE.csh spacewarp_2013-08-08.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: 665 subjects were already retired and can be ignored
# SWAPSHOP: if you want, you can go ahead and retire 3416 subjects with 

SWITCH.py CFHTLS_allfuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-08-09 (Friday) 14:34 PDT

SWIPE.csh spacewarp_2013-08-09.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 3118 subjects with

SWITCH.py CFHTLS_allfuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-08-12 (Monday) 15:52 PDT

SWIPE.csh spacewarp_2013-08-12.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 5864 subjects with

SWITCH.py CFHTLS_allfuzzy_retire_these.txt > retirement.log &

# Also, start fuzzy processing again, for comparison. Possible to run both?
# Want to switch back to the hasty processing, in order to keep 
# selection function clean. Run fuzzy from the beginning! Probably should do 
# this on Weds, when we have lots of time... Start early at SLAC, then
# leave while at football. Pick up laptop on the way home.

# ======================================================================
# 2013-08-13 (Tuesday) 13:44 PDT

SWIPE.csh spacewarp_2013-08-13.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1540 subjects with

SWITCH.py CFHTLS_allfuzzy_retire_these.txt > retirement.log &

# ======================================================================
# 2013-08-14 (Wednesday) 10:36 PDT

# OK, switching back to hasty analysis, in analysis/hasty !

# First kill off old mongo, in allfuzzy:
\rm -rf spacewarp_2013-08-13* mongo

# Then:

cd ../hasty

SWIPE.csh spacewarp_2013-08-14.gz

# Edit startup.config to make hasty standard. Then run swapshop:

SWAPSHOP.csh -s CFHTLS --fast --startup

# OK, started at 12:27 PDT, finished 12.5 hours later!

# SWAPSHOP: previous run brought total retirements to:
#        0 CFHTLS_hasty_previously_retired.txt
# SWAPSHOP: current run has suggested another batch:
#   283791 CFHTLS_hasty_retire_these.txt
# SWAPSHOP: after checking for uniqness, we need to retire these:
#   283791 CFHTLS_hasty_retire_these.txt
# SWAPSHOP: 0 subjects were already retired and can be ignored
# SWAPSHOP: if you want, you can go ahead and retire 283791 subjects with

# Stats from the report are:
# 
# Number of classifications: 	7924951
# Number of classns used: 		2845249
# Number of classifiers: 		31808
# Number of test subjects: 		295030
# Number of sims: 				3895
# Number of duds: 				3150
#  
# Mean test classns/classifier:	223.8 
# Mean classns/test subject:	9.2 
# Test subject retirements:		283791 
# Mean classns/retirement:		9.1 
# Test subject rejections:		283791 
# Test subject identifications:	2315
# Lens completeness:			91.7% 
# Lens purity:					0.2% 
# FP contamination:				99.8%
# Lenses missed (FN rate):		7.9%

# OK, now need to compare hasty retirements with most recent allfuzzy list, 
# as above. 

# From above: 
#  Take the previously retired list, and remove the 
#  subjects that appear in the fuzzy retirement list.
# The leftovers are to be resurrected!

set resurrections = CFHTLS_hasty_resurrect_these.txt
set allfuzzyretirements = ../allfuzzy/CFHTLS_2013-08-13_10:01:43/CFHTLS_2013-08-13_10:01:43_retire_these.txt
set hastyretirements = ../hasty/CFHTLS_2013-08-14_10:03:28/CFHTLS_2013-08-14_10:03:28_retire_these.txt
set newretirements = CFHTLS_hasty_actually_retire_these.txt

set count = 0
\rm -f $resurrections
foreach subject ( `cat $allfuzzyretirements` )
   set k = `grep $subject $hastyretirements | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k == 0) then
       echo $subject >> $resurrections
   endif
end
echo "$count allfuzzy subjects already happily retired, can be ignored" ; \
echo "List of subjects to be resurrected:" ; \
wc -l $resurrections

# 279390 allfuzzy subjects already happily retired, can be ignored
# List of subjects to be resurrected:
#      840 CFHTLS_hasty_resurrect_these.txt


# Now look for new retirements, by doing the cross-check the other way:

set count = 0
\rm -f $newretirements
foreach subject ( `cat $hastyretirements` )
   set k = `grep $subject $allfuzzyretirements | wc -l`
   if ($k == 1) then
       @ count = $count + $k
   else if ($k == 0) then
       echo $subject >> $newretirements
   endif
end
echo "$count hasty subjects already happily retired, can be ignored" ; \
echo "List of subjects to be retired:" ; \
wc -l $newretirements

# 279390 hasty subjects already happily retired, can be ignored
# List of subjects to be retired:
#     4401 CFHTLS_hasty_actually_retire_these.txt

# Next time around, the $hastyretirements list will get copied into the 
# previously retired list, so no need to copy manually. 

# Now SWITCH! 

SWITCH.py -r CFHTLS_hasty_resurrect_these.txt >& CFHTLS_hasty_resurrect_these.log 

# Done.

SWITCH.py CFHTLS_hasty_actually_retire_these.txt >& CFHTLS_hasty_actually_retire_these.log

# Pending...

# Meanwhile, in the allfuzzy directory, run SWAPSHOP to keep the pickles
# up to date.

cd $SWAP_DIR/allfuzzy
SWAPSHOP.csh -s CFHTLS --fast

# Save transfer files:

cd $SWAP_DIR/hasty

mkdir transfer
mv CFHTLS_hasty_actually_retire_these.* transfer/
mv CFHTLS_hasty_resurrect_these.* transfer/
cp CFHTLS_hasty_* transfer/


# ======================================================================
# 2013-08-16 (Friday) 09:09 PDT

# New regime: both hasty and allfuzzy!

SWIPE.csh spacewarp_2013-08-16.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2489 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log &

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-17 (Saturday) 15:25 PDT

SWIPE.csh spacewarp_2013-08-17.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 863 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log &

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-18 (Sunday) 09:41 PDT

SWIPE.csh spacewarp_2013-08-18.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 715 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-19 (Monday) 10:34 PDT

SWIPE.csh spacewarp_2013-08-19.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 502 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-20 (Tuesday) 09:32 PDT

SWIPE.csh spacewarp_2013-08-20.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 457 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-21 (Wednesday) 13:08 PDT

SWIPE.csh spacewarp_2013-08-21.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 352 subjects with
# Low because D8 is now in play...

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-22 (Thursday) 10:48 PDT

SWIPE.csh spacewarp_2013-08-22.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 424 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-23 (Friday) 08:56 PDT

SWIPE.csh spacewarp_2013-08-23.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 766 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-24 (Saturday) 10:13 PDT

SWIPE.csh spacewarp_2013-08-24.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAP: updating all subjects with classifications made since 2013-08-23_10:14:02
# SWAP: should we use the marker positions on sims?  True
# SWAP: read an old bureau of 32175 classification agents from ./CFHTLS_bureau.pickle
# SWAP: read an old collection of 326666 subjects from ./CFHTLS_collection.pickle
# SWAP: interpreting up to 50000  classifications...
# 
# SWAP: total no. of classifications processed:  0
# SWAP: something went wrong - 0 classifications found.

# SWIPE: mongorestoring into database 'ouroboros_staging'
# SWIPE: mongorestore log stored in .spacewarp_2013-08-24_mongorestore.log
# SWIPE: ERROR: failed to restore database, exiting

# Hmm - not sure why. Trash 24, make diskspace, try 25.

# ======================================================================
# 2013-08-25 (Sunday) 15:33 PDT

SWIPE.csh spacewarp_2013-08-25.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1547 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-26 (Monday) 17:20 PDT

SWIPE.csh spacewarp_2013-08-26.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1369 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-27 (Tuesday) 08:47 PDT

SWIPE.csh spacewarp_2013-08-27.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1925 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-28 (Wednesday) 17:24 PDT

SWIPE.csh spacewarp_2013-08-28.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2398 subjects with
# That's better!

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-29 (Thursday) 10:29 PDT

SWIPE.csh spacewarp_2013-08-29.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2089 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-08-30 (Friday) 14:29 PDT

SWIPE.csh spacewarp_2013-08-30.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1675 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-09-01 (Sunday) 18:38 PDT

SWIPE.csh spacewarp_2013-09-01.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 4024 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-09-02 (Monday) 11:09 PDT

SWIPE.csh spacewarp_2013-09-02.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1935 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# ======================================================================
# 2013-09-03 (Tuesday) 11:56 PDT

SWIPE.csh spacewarp_2013-09-03.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2303 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Now update allfuzzy pickles:

cd $SWAP_DIR/allfuzzy

SWAPSHOP.csh -s CFHTLS --fast

cd $SWAP_DIR/hasty

# Damn - allfuzzy pickles are corrupted :-/ Will need to be restarted.

# ======================================================================
# 2013-09-04 (Wednesday) 11:09 PDT

# Hasty-only analysis.

SWIPE.csh spacewarp_2013-09-04.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2003 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-06 (Friday) 12:13 PDT

SWIPE.csh spacewarp_2013-09-06.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# Oops, this SWIPE failed. 

# ======================================================================
# 2013-09-07 (Saturday) 13:33 PDT

SWIPE.csh spacewarp_2013-09-07.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 7896 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-09 (Monday) 12:17 PDT

SWIPE.csh spacewarp_2013-09-09.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 5449 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-10 (Tuesday) 09:24 PDT

SWIPE.csh spacewarp_2013-09-10.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1087 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-11 (Wednesday) 09:58 PDT

SWIPE.csh spacewarp_2013-09-11.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1094 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-12 (Thursday) 12:30 PDT

SWIPE.csh spacewarp_2013-09-12.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1213 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-13 (Friday) 10:14 PDT

SWIPE.csh spacewarp_2013-09-13.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1737 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-15 (Sunday) 18:47 PDT

SWIPE.csh spacewarp_2013-09-15.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 4421 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-16 (Monday) 08:38 PDT

SWIPE.csh spacewarp_2013-09-16.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 3402 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-17 (Tuesday) 09:33 PDT

SWIPE.csh spacewarp_2013-09-17.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2234 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-18 (Wednesday) 12:28 PDT

SWIPE.csh spacewarp_2013-09-18.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2539 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-19 (Thursday) 10:56 PDT

SWIPE.csh spacewarp_2013-09-19.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1965 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-20 (Friday) 09:41 PDT

sleep 600

SWIPE.csh spacewarp_2013-09-20.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2136 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-23 (Monday) 08:33 PDT

SWIPE.csh spacewarp_2013-09-23.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 5722 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-24 (Tuesday) 09:39 PDT

SWIPE.csh spacewarp_2013-09-24.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1921 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-25 (Wednesday) 11:09 PDT

SWIPE.csh spacewarp_2013-09-25.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2039 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-26 (Thursday) 12:23 PDT

SWIPE.csh spacewarp_2013-09-26.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1922 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-27 (Friday) 10:10 PDT

SWIPE.csh spacewarp_2013-09-27.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1863 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-09-29 (Sunday) 17:31 PDT

SWIPE.csh spacewarp_2013-09-29.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 4207 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-01 (Tuesday) 10:34 PDT

SWIPE.csh spacewarp_2013-10-01.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 4739 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-02 (Wednesday) 08:09 PDT

SWIPE.csh spacewarp_2013-10-02.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1478 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-03 (Thursday) 17:58 PDT

SWIPE.csh spacewarp_2013-10-03.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-04 (Friday) 16:04 PDT

SWIPE.csh spacewarp_2013-10-04.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1859 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-07 (Monday) 01:08 PDT

SWIPE.csh spacewarp_2013-10-06.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 3805 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-07 (Monday) 08:37 PDT

SWIPE.csh spacewarp_2013-10-07.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1741 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-08 (Tuesday) 14:13 CEST

SWIPE.csh spacewarp_2013-10-08.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1361 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-09 (Wednesday) 14:12 PDT

SWIPE.csh spacewarp_2013-10-09.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1691 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-10 (Thursday) 11:33 PDT

SWIPE.csh spacewarp_2013-10-10.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1550 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-11 (Friday) 09:09 PDT

SWIPE.csh spacewarp_2013-10-11.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-14 (Monday) 08:47 PDT

SWIPE.csh spacewarp_2013-10-14.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 4186 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-16 (Wednesday) 11:20 PDT

SWIPE.csh spacewarp_2013-10-16.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-17 (Thursday) 12:33 PDT

SWIPE.csh spacewarp_2013-10-17.gz

# Argh - pickles corrupted. Redo all hasty analysis. 

SWAPSHOP.csh -s CFHTLS --fast --startup
# SWAPSHOP: if you want, you can go ahead and retire 392430 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-19 (Saturday) 10:12 PDT

SWIPE.csh spacewarp_2013-10-18.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1069 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-21 (Monday) 11:23 PDT

SWIPE.csh spacewarp_2013-10-21.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 4499 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-22 (Tuesday) 14:27 PDT

SWIPE.csh spacewarp_2013-10-22.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2013 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-23 (Wednesday) 15:49 PDT

SWIPE.csh spacewarp_2013-10-23.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1025 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-24 (Thursday) 13:29 PDT

SWIPE.csh spacewarp_2013-10-24.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1719 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-25 (Friday) 11:59 PDT

SWIPE.csh spacewarp_2013-10-25.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1491 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-28 (Monday) 11:24 PDT

SWIPE.csh spacewarp_2013-10-28.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 4245 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-29 (Tuesday) 13:49 CDT

SWIPE.csh spacewarp_2013-10-29.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1488 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-10-30 (Wednesday) 11:03 CDT

SWIPE.csh spacewarp_2013-10-30.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 933 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-02 (Saturday) 09:51 PDT

SWIPE.csh spacewarp_2013-11-01.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 2402 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-04 (Monday) 09:31 PST

SWIPE.csh spacewarp_2013-11-04.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 3073 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-05 (Tuesday) 09:38 PST

SWIPE.csh spacewarp_2013-11-05.gz
# x spacewarp_2013-11-05/spacewarp_classifications.bson: Truncated tar archive
# tar: Error exit delayed from previous errors.

# Hmm - see if tomorrow's is better...

# ======================================================================
# 2013-11-06 (Wednesday) 10:07 PST

SWIPE.csh spacewarp_2013-11-06.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 1511 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-07 (Thursday) 08:32 PST

SWIPE.csh spacewarp_2013-11-07.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 680 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-08 (Friday) 12:47 PST

SWIPE.csh spacewarp_2013-11-08.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 442 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-09 (Saturday) 13:24 PST

SWIPE.csh spacewarp_2013-11-09.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 414 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-11 (Monday) 09:35 PST

SWIPE.csh spacewarp_2013-11-11.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAP: something went wrong - 0 classifications found.

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-14 (Thursday) 09:52 PST

SWIPE.csh spacewarp_2013-11-14.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 784 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-15 (Friday) 14:13 PST

SWIPE.csh spacewarp_2013-11-15.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-18 (Monday) 11:02 PST

SWIPE.csh spacewarp_2013-11-18.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-19 (Tuesday) 12:06 PST

SWIPE.csh spacewarp_2013-11-19.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-20 (Wednesday) 14:52 PST

SWIPE.csh spacewarp_2013-11-20.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 30 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-21 (Thursday) 10:04 PST

SWIPE.csh spacewarp_2013-11-21.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 46 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-22 (Friday) 11:45 PST

sleep 500
SWIPE.csh spacewarp_2013-11-22.gz && \
SWAPSHOP.csh -s CFHTLS --fast && \
SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# SWAPSHOP: if you want, you can go ahead and retire 20 subjects with

# There's something funny going on here - 13,000 classifications and
# only 20 retirements?

# Probably we are down to the detections and the undecideds! Finishing
# criterion may need resetting - via max classifications = 20?

# ======================================================================
# 2013-11-25 (Monday) 08:35 PST

SWIPE.csh spacewarp_2013-11-25.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 77 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-26 (Tuesday) 12:11 PST

SWIPE.csh spacewarp_2013-11-26.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 14 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-27 (Wednesday) 12:59 PST

SWIPE.csh spacewarp_2013-11-27.gz

SWAPSHOP.csh -s CFHTLS --fast
# SWAPSHOP: if you want, you can go ahead and retire 31 subjects with

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# ======================================================================
# 2013-11-27 (Wednesday) 15:02 PST

# Investigating undecideds. Hampered by SWAP's enormous (1.8Gb!) pickle,
# so try developing in a testplots directory having run SWAP on just the 
# autumn data (since Nov 1).

mkdirf testplots
cp ../hasty/startup.config autumn.config

# Edited startup.config...

SWAP.py autumn.config

# Takes some time to get to the right part of teh file... Then does 50k,
# and stops. Good! Now have pickles for plot testing.

SWAG.py update.config

# This worked well for testing. Then I upgraded SWAP to output catalogs with
# probabilities, and an extra trajectories plot showing *all* the 
# undecided/detected test subjects, sims and duds. 
# I ran SWAP on a copy of update.config, that had report=True and
# repickle=False:

SWAP.py plot.config

# ...
# SWAP: updating all subjects with classifications made since 2013-11-27_10:20:43
# SWAP: read an old bureau of 36536 classification agents from ./CFHTLS_bureau.pickle
# SWAP: read an old collection of 437276 subjects from ./CFHTLS_collection.pickle
# ...
# SWAP: saving lens candidates...
# SWAP: 3348 lines written to /Users/pjm/public_html/SpaceWarps/Science/analysis/hasty/CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_candidates.txt
# ...
# SWAP: saving catalog of high probability subjects...
# SWAP: From 437276 subjects classified,
# SWAP: 6409 candidates (with P > rejection) written to /Users/pjm/public_html/SpaceWarps/Science/analysis/hasty/CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_candidate_catalog.txt
# SWAP: saving catalog of high probability subjects...
# SWAP: From 437276 subjects classified,
# SWAP: 5337 sim 'candidates' (with P > rejection) written to /Users/pjm/public_html/SpaceWarps/Science/analysis/hasty/CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_sim_catalog.txt
# SWAP: saving catalog of high probability subjects...
# SWAP: From 437276 subjects classified,
# SWAP: 5 dud 'candidates' (with P > rejection) written to /Users/pjm/public_html/SpaceWarps/Science/analysis/hasty/CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_dud_catalog.txt
# ...
# SWAP: plotting 500 candidates in /Users/pjm/public_html/SpaceWarps/Science/analysis/hasty/CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_sample.png
# SWAP: plotting 500 sims in /Users/pjm/public_html/SpaceWarps/Science/analysis/hasty/CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_sample.png
# SWAP: plotting 5 duds in /Users/pjm/public_html/SpaceWarps/Science/analysis/hasty/CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_sample.png

# So, 3348 candidates, (6409-3348) = 3061 undecideds.

# OK, look at completeness as a function of probability threshold.
# 5712 sims in total: 5337 sim candidates = 93.4% completeness 

set candidatecat = CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_candidate_catalog.txt
set simcat = CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_sim_catalog.txt

set thresholds = ( 0.01 0.05 0.10 0.25 0.50 0.90 0.95 )

foreach threshold ( $thresholds )
   set Ncandidates = `grep -v '#' $candidatecat | awk '{if ($2 > '$threshold') print $1}' | wc -l`
   set Nsims = `grep -v '#' $simcat | awk '{if ($2 > '$threshold') print $1}' | wc -l`
   set completeness = `echo $Nsims 5712 | awk '{printf "%.1f\n", 100.0*$1/$2}'`
   echo "P > ${threshold}: ${Ncandidates} candidates at ${completeness}% completeness"
end

# P > 0.01: 3837 candidates at 93.0% completeness
# P > 0.05: 3675 candidates at 92.9% completeness
# P > 0.10: 3609 candidates at 92.9% completeness
# P > 0.25: 3514 candidates at 92.9% completeness
# P > 0.50: 3456 candidates at 92.8% completeness
# P > 0.90: 3358 candidates at 92.8% completeness
# P > 0.95: 3348 candidates at 92.8% completeness

# Interesting. I think this shows that accepting candidates below 
# P = 0.95 is barely worth it - we're adding a lot of noise for very little
# gain in completeness. Distribution of P's is highly bimodal!

# How many subjects have P > rejection, P < detection and Nclass < 20?

grep -v '#' $candidatecat | awk '{if ($2 < 0.95 && $3 < 20) print $1}' | wc -l
#     1403
grep -v '#' $candidatecat | awk '{if ($2 < 0.95 && $3 < 10) print $1}' | wc -l
#     1062

# This is how many "unfinished" subjects there are. If we set
# max_classifications to 20, we only have 1403 images to go. Request from
# Michael!

# OK, what about even better samples? Can we select at P > 99%?

set thresholds = ( 0.95 0.96 0.97 0.99 0.995 0.999 )

foreach threshold ( $thresholds )
   set Ncandidates = `grep -v '#' $candidatecat | awk '{if ($2 > '$threshold') print $1}' | wc -l`
   set Nsims = `grep -v '#' $simcat | awk '{if ($2 > '$threshold') print $1}' | wc -l`
   set completeness = `echo $Nsims 5712 | awk '{printf "%.1f\n", 100.0*$1/$2}'`
   echo "P > ${threshold}: ${Ncandidates} candidates at ${completeness}% completeness"
end

# P > 0.95: 3348 candidates at 92.8% completeness
# P > 0.96: 2921 candidates at 82.9% completeness
# P > 0.97: 2463 candidates at 71.8% completeness
# P > 0.99: 1153 candidates at 37.6% completeness
# P > 0.995: 581 candidates at 23.8% completeness
# P > 0.999: 37 candidates at 2.2% completeness

# Interesting: 0.95 looks somewhat special, the completeness drops off above
# that number. What do the 0.999 systems look like? ~ the top 40?

mkdir -p top40
set urls = `grep -v '#' $candidatecat | awk '{if ($2 > 0.999) print $4}'`
foreach url ( $urls )
  set x = `grep $url $candidatecat`
  set png = "top40/${x[1]}.png"
  wget -O $png -o junk $url 
  du -h $png
end
cd top40
gallery.pl -o top40.pdf -x 2 -y 2 -pdf -t *png

# Hah! Only a few look like solid lenses. Stage 1 P is noisy...

# ======================================================================
# 2013-12-02 (Monday) 15:33 PST

# Look up probabilities of real lenses!
# Do this in hasty directory.

set manifest = /Users/pjm/public_html/SpaceWarps/Science/training/SpottersGuide/CFHTLS/knownlenses/listfiles_d1_d11
set lenscat = /Users/pjm/public_html/SpaceWarps/Science/training/SpottersGuide/CFHTLS/knownlenses/finlenscat_updated.txt
set candidatecat = CFHTLS_2013-11-27_10:20:43/CFHTLS_2013-11-27_10:20:43_candidate_catalog.txt

\rm -f junk*
foreach stem ( `grep -v '#' $lenscat | awk '{print $1}'` )
  set zooid = `grep $stem $manifest | awk '{print $3}'`
  foreach k ( 2 3 )
    set altstem = `echo $stem | sed s/CFHTLS_0/CFHTLS_$k/g | sed s/CFHTLS_1/CFHTLS_$k/g`
    set altzooid = `grep $altstem $manifest | awk '{print $3}'`
    if ($#altzooid) then
      set stem = $altstem
      set zooid = $altzooid
    endif
  end
  grep $zooid $candidatecat >> junk1
  grep $stem $lenscat >> junk2
  grep $zooid $manifest >> junk3
end

# Note how we had to check for teh alt ids, for teh subjects that have real 
# lenses in them AND had sims put in them. The later ids are from D11, when
# we put these subjects back in without sims.

paste junk1 junk2 junk3 > ${candidatecat:r}_knownlenses.txt
# This is wrong - the components don't match up!

wc -l junk*     
     133 junk1
     199 junk2
     216 junk3

# How many real lenses are there?
awk '{print $1}' junk2 | sort -n | uniq | wc -l
# 163
# So not 216!...

# And how many are candidates?
awk '{print $1}' junk1 | sort -n | uniq | wc -l
#       121

# So, 121 out of 163 - 74%.

# Grab 2 columns, uniq by 1 and sort by 2?

awk '{print $1,$2}' junk1 | sort -n | uniq | sort -rn -k2 | tail -20
# ASW0004p94 0.9515456
# ASW00099md 0.9510602
# ASW0009cro 0.5296275
# ASW0005aj2 0.0881583
# ASW0009clg 0.0525023
# ASW0000dlz 0.0206259
# ASW0009bn8 0.0059907
# ASW00056pq 0.0011886
# ASW000037r 0.0004669
# ASW00099dy 0.0004428
# ASW0009d7g 0.0000261
# ASW0008mw7 0.0000027

# OK: all but 10 have P > 0.95!
# So 111 make candidates list, out of 163: 68% complete. 
# Full catalog including undecideds is 121/163 = 74% complete.

# BUG: some "lenses" in the lenscat are actually training images (they 
# had sims put in them!) - so they do not appear in the candidate catalog,
# just because they are not test subjects. Caught and reran, code above is
# now correct.

# ======================================================================
# 2013-12-04 (Wednesday) 07:31 EST

# Make galleries of real lenses that are detected, undecided and rejected

mkdir -p detected
cd detected
set detected = `awk '{if ($2 > 0.95) print $1}' ../junk1 | sort -n | uniq`
set pngs = ()
foreach subject ( $detected )
  set url = `grep $subject ../junk1 | head -1 | awk '{print $4}'`
  set zooid = `grep $subject ../junk1 | head -1 | awk '{print $1}'`
  wget -O ${zooid}.png "$url"
  set pngs = ( $pngs ${zooid}.png )
end
gallery.pl -pdf -x 2 -y 2 -t -o gallery_detected.pdf $pngs
cd ../

# set new = `ls $pngs | & grep directory | cut -d':' -f2 | cut -d'.' -f1`
# foreach subject ( $new )
#   set url = `grep $subject ../junk1 | head -1 | awk '{print $4}'`
#   set zooid = `grep $subject ../junk1 | head -1 | awk '{print $1}'`
#   wget -O ${zooid}.png "$url"
# end


mkdir -p undecided
cd undecided
set undecided = `awk '{if ($2 < 0.95) print $1}' ../junk1 | sort -n | uniq`
set pngs = ()
foreach subject ( $undecided )
  set url = `grep $subject ../junk1 | head -1 | awk '{print $4}'`
  set zooid = `grep $subject ../junk1 | head -1 | awk '{print $1}'`
  wget -O ${zooid}.png "$url"
  set pngs = ( $pngs ${zooid}.png )
end
gallery.pl -pdf -x 2 -y 2 -t -o gallery_undecided.pdf $pngs
cd ../

# set new = `ls $pngs | & grep directory | cut -d':' -f2 | cut -d'.' -f1`
# foreach subject ( $new )
#   set url = `grep $subject ../junk1 | head -1 | awk '{print $4}'`
#   set zooid = `grep $subject ../junk1 | head -1 | awk '{print $1}'`
#   wget -O ${zooid}.png "$url"
# end


mkdir -p rejected
cd rejected
set lenses = ( $detected $undecided )
set all = `awk '{print $3}' ../junk3 | sort -n | uniq`
set pngs = ()
foreach subject ( $all )
  set k = 0
  set ignore = 0
  while ($k < $#lenses) 
    @ k = $k + 1
    if ($subject == $lenses[$k]) then
      set ignore = 1
      set k = 100000
    endif
  end
  if ($ignore == 0) then  
    set url = `grep $subject ../junk3 | head -1 | awk '{print $1}'`
    set zooid = `grep $subject ../junk3 | head -1 | awk '{print $3}'`
    # wget -N -O ${zooid}.png "$url"
    set pngs = ( $pngs ${zooid}.png )
  endif  
end
gallery.pl -pdf -x 2 -y 2 -t -o gallery_rejected.pdf $pngs
cd ../

# set new = `ls $pngs | & grep directory | cut -d':' -f2 | cut -d'.' -f1`
# foreach subject ( $new )
#   set url = `grep $subject ../junk3 | head -1 | awk '{print $1}'`
#   set zooid = `grep $subject ../junk3 | head -1 | awk '{print $3}'`
#   wget -O ${zooid}.png "$url"
# end


# ======================================================================
# 2013-12-08 (Sunday) 15:32 GMT

# In Oxfordshire, haven't run for a while!

SWIPE.csh spacewarp_2013-12-08.gz

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# SWAP: interpreting up to 50000  classifications...
# SWAP: 
# SWAP: total no. of classifications processed:  1

# Something wrong...
# Mongo was the old one, from doing the testplots. Killed it, can now 
# move on!

SWAPSHOP.csh -s CFHTLS --fast

SWITCH.py CFHTLS_hasty_retire_these.txt > retirement.log

# OK good! 100 more retirements.

# Now have 3381 candidates - send these to Adler for Stage 2!
# Final analysis time is CFHTLS_2013-12-08_10:20:56

# Cut catalog at 0.95:

set cat = CFHTLS_2013-12-08_10:20:56/CFHTLS_2013-12-08_10:20:56_candidate_catalog.txt

set finalcat = CFHTLS_2013-12-08_10:20:56_good_candidate_catalog.txt

head -1 $cat > $finalcat
grep -v '#' $cat | awk '{if ($2 > 0.95) print $0}' >> $finalcat

# Make a copy in Science folder...
cp $finalcat ../stage1_results/.
cp -r CFHTLS_2013-12-08_10:20:56/* ../stage1_results/

# ======================================================================
# 2013-12-10 (Tuesday) 13:22 GMT

# Test stage 2 labels in database:

cd ../stage2_test

SWIPE.csh stage2_2013-12-03.tar.gz

SWAPSHOP.csh -s CFHTLS --startup --fast --stage2

# No classifications read in - possibly due to name changes? (Parrish)
# Retry with live database tomorrow.

# ======================================================================
# 2013-12-11 (Wednesday) 12:02 GMT

cd ../stage2

SWIPE.csh spacewarp_2013-12-11.gz

SWAPSHOP.csh -s CFHTLS --startup --fast --stage2

# Good - runs OK! Aborted, restarted with printing turned off. Will be slow at
# first as it has to page through all classifications since the_beginning
# - so manually edited startup.config to avouid this (and commented
# out the copy from swap dir in SWAPSHOP)
# Used:
#   start: 2013-12-10_00:00:00

# Hmm - what time zone is this? Would be good to have a more accurate 
# start time...

# Anyway, classifications are not being correctly recognised as stage 2 by 
# SWAP. Here's an example:

Found classification from different stage:  ('2013-12-11_00:09:55',
'51f5063e0aab2a718b00000c', '5183f151e4bb210219045886', 'ASW00063ra', 'test',
'test', 'NOT', 'UNKNOWN',
'http://spacewarps.org/subjects/standard/5183f151e4bb210219045886.png', 1)

# Switched to taking stage from metadata.

# Looks like classifier.coffee is not labelling classifications correctly:

WARNING: classification labelled stage 1, while subject is stage 2
Found classification from this stage:  ('2013-12-11_10:20:33', '109.30.36.48',
'5183f151e4bb21021900e52b', 'ASW000199n', 'test', 'test', 'NOT', 'UNKNOWN',
'http://spacewarps.org/subjects/standard/5183f151e4bb21021900e52b.png', 2)

# And also, here's a classification of a stage 1 subject! 

Found classification from different stage:  ('2013-12-11_10:20:33',
'109.30.36.48', '5183f151e4bb21021904738b', 'ASW000693f', 'training', 'sim',
'NOT', 'LENS',
'http://spacewarps.org/subjects/standard/5183f151e4bb21021904738b.png', 1)

# DAMN. Some training images are still labelled stage 1.
# AND: No classifications are labelled stage 2! 
# FUCK. Now we have to use timestamps.

# Re-run and save output, then browse to find first timestamp.

SWAPSHOP.csh -s CFHTLS --startup --fast --stage2 >& swap.log &

# Looks like magic start time was:

# 2013-12-10_13:29:41

# Set this as start time in stage2.config and edit SWAPSHOP to read it

# Now re-run looking at classifications to see if stage is labelled...

\rm -rf CFHTLS_* swap.log update.config

SWAPSHOP.csh -s CFHTLS --startup --fast --stage2 --config stage2.config >& swap.log &

# Ohhhhh it's an ANNOTATION:

# {u'_id': ObjectId('52a759815b6a137dd400021a'), u'user_id':
# ObjectId('50ef25bc6b34c90aab000017'), u'created_at': datetime.datetime(2013,
# 12, 10, 18, 12, 17), u'updated_at': datetime.datetime(2013, 12, 10, 18, 12,
# 17, 343000), u'user_ip': u'94.3.55.144', u'workflow_id':
# ObjectId('528107773ae7400fd4000001'), u'subjects': [{u'zooniverse_id':
# u'ASW0001gfp', u'coords': [], u'id': ObjectId('5183f151e4bb210219010975'),
# u'location': {u'thumbnail':
# u'http://spacewarps.org/subjects/thumbnail/5183f151e4bb210219010975.png',
# u'standard':
# u'http://spacewarps.org/subjects/standard/5183f151e4bb210219010975.png'}}],
# u'subject_ids': [ObjectId('5183f151e4bb210219010975')], u'project_id':
# ObjectId('5101a1341a320ea77f000001'), u'user_name': u'coulditbemanilow',
# u'annotations': [{u'stage': u'2'}, {u'finished_at': u'Tue, 10 Dec 2013
# 18:12:14 GMT', u'started_at': u'Tue, 10 Dec 2013 18:10:59 GMT'},
# {u'user_agent': u'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:25.0) Gecko/20100101
# Firefox/25.0'}, {u'lang': u'en'}]}

# Edit SWAP and try again:

\rm -rf CFHTLS_* swap.log update.config

SWAPSHOP.csh -s CFHTLS --startup --fast --stage2 --config stage2.config >& swap.log &

# Did we get any stage 1 subject warnings?
# Yes:

# WARNING: classification labelled stage 1, while subject is stage 2!
# Found classification from different stage:  1  cf.  2 , items = 
# ('2013-12-10_16:30:38', '52a735e65b6a1304ad00005b',
# '5183f151e4bb210219068fd0', 'ASW00097tc', 'test', 'test', 'LENS', 'UNKNOWN',
# 'http://spacewarps.org/subjects/standard/5183f151e4bb210219068fd0.png', '1')

grep WARNING swap.log | wc -l
#      651

# Set SWAP to ignore these completely.

# First correct stage 2 classification is this one:

# Found classification from this stage:  ('2013-12-10_16:47:03',
# '503f1bff0454e20bf40004b3', '5183f151e4bb21021905aa13', 'ASW0007yfn', 'test',
# 'test', 'NOT', 'UNKNOWN',
# 'http://spacewarps.org/subjects/standard/5183f151e4bb21021905aa13.png', '2')

# Use this time in stage2.config instead! 2013-12-10_16:47:00

# Looks like times are GMT! (Or perhaps UTC?)


# OK, need to read things in subject metadata properly, to interpret 
# false positives. What words are used?

\rm -rf CFHTLS_* swap.log update.config

SWAPSHOP.csh -s CFHTLS --startup --fast --stage2 --config stage2.config >& swap.log &

# Great. Noticed this was done in hasty mode - want to turn this off, 
# to use all classifications and reduce false neg rate! Re-ran, ready for 
# production.

# ======================================================================
# 2013-12-12 (Thursday) 12:54 GMT

SWIPE.csh spacewarp_2013-12-12.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2

# Good - first five candidates! Start downloading images, based on 
# cands catalog (ie into informatively named files!)

open `grep -v '#'  CFHTLS_2013-12-12_10:23:40/CFHTLS_2013-12-12_10:23:40_candidate_catalog.txt | \
        awk '{if ($2 > 0.95) printf "http://talk.spacewarps.org/#/subjects/%s\n", $1}'

# Add to download script...

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download

# ======================================================================
# 2013-12-13 (Friday) 12:23 GMT

SWIPE.csh spacewarp_2013-12-13.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download

# ======================================================================
# 2013-12-16 (Monday) 11:14 GMT

SWIPE.csh spacewarp_2013-12-15.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download


SWIPE.csh spacewarp_2013-12-16.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download

# ======================================================================
# 2013-12-17 (Tuesday) 12:28 GMT

SWIPE.csh spacewarp_2013-12-17.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download

# ======================================================================
# 2013-12-18 (Wednesday) 14:36 GMT

SWIPE.csh spacewarp_2013-12-18.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download

# ======================================================================
# 2013-12-19 (Thursday) 14:28 GMT

SWIPE.csh spacewarp_2013-12-19.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download

# ======================================================================
# 2013-12-29 (Sunday) 18:30 PST

SWIPE.csh spacewarp_2013-12-29.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download

# ======================================================================
# 2014-01-07 (Tuesday) 17:34 PST

# Been a while, but here's the final stage 2 database. It contains some 
# VICS82 classifications, but they are labelled stage 1 so shouldn't feature. 
# Turned on stage 1 warning, just to see them!

SWIPE.csh spacewarp_2014-01-07.gz 

SWAPSHOP.csh -s CFHTLS --fast --stage2 --download

# Run this before doing VICS82 stuff - doesn't take long.

# Good news - stage flagged OK:

# SWAP: ....................WARNING: classification labelled stage 1, while subject is stage 2!
# WARNING: classification labelled stage 1, while subject is stage 2!
# WARNING: classification labelled stage 1, while subject is stage 2!
# WARNING: classification labelled stage 1, while subject is stage 2!
# WARNING: classification labelled stage 1, while subject is stage 2!
# WARNING: classification labelled stage 1, while subject is stage 2!
# WARNING: classification labelled stage 1, while subject is stage 2!
# WARNING: classification labelled stage 1, while subject is stage 2!
# .........................
# SWAP: total no. of classifications processed:  31034

# However, subsequent runs of SWAP fail for some reason. 0 classifications
# found? Some problem with final timestamp?

# Check out candidates: 

ls candidates/*png | wc -l
#       88

# But, some of the downloaded images are empty - maybe because they were
# supposed to be VICS82 ones?! Look at catalog:

du -h candidates/*png | grep 0B
#   0B    candidates/ASW0000ctm.png
#   0B    candidates/ASW000234o.png
#   0B    candidates/ASW0002bmc.png
#   0B    candidates/ASW0002qtn.png
#   0B    candidates/ASW0003mb7.png
#   0B    candidates/ASW00047ae.png
#   0B    candidates/ASW00048x4.png
#   0B    candidates/ASW00059a7.png
#   0B    candidates/ASW0005kad.png
#   0B    candidates/ASW0005lmz.png
#   0B    candidates/ASW0005u1n.png
#   0B    candidates/ASW00062bc.png
#   0B    candidates/ASW0006e0o.png
#   0B    candidates/ASW0006ker.png
#   0B    candidates/ASW0006ksp.png
#   0B    candidates/ASW0006ktg.png
#   0B    candidates/ASW00072kz.png
#   0B    candidates/ASW00078we.png
#   0B    candidates/ASW0007e08.png
#   0B    candidates/ASW0007sez.png
#   0B    candidates/ASW0007u3n.png
#   0B    candidates/ASW0007uda.png
#   0B    candidates/ASW0007vx2.png
#   0B    candidates/ASW0008mtv.png
#   0B    candidates/ASW0009a68.png
#   0B    candidates/ASW0009bq9.png
#   0B    candidates/ASW0009coy.png

# check talk...

ASW0009coy is CFHTLS
ASW0006ker is CFHTLS

# Probably these are all stage 2 candidates, but server is refusing image
# requests... check logs:

more candidates/.ASW0009coy.log
# --2013-12-29 19:44:04--  http://spacewarps.org/subjects/standard/5183f151e4bb21021906a882.png
# Resolving spacewarps.org... failed: nodename nor servname provided, or not known.
# wget: unable to resolve host address `spacewarps.org'

# Whoah! Tested wgetting one, and it worked OK. Phew. Need to redownload 
# these, preferably by re-running SWAP sometime...

# Now though, need to focus on VICS82! 
# Start downloading new dump, try reading VICS82 classifications.

# ======================================================================
# 2014-01-07 (Tuesday) 21:18 PST

# Run SWAP in VICS82/stage1 directory - testing for project!

SWAPSHOP.csh -s VICS82 --startup --fast --config stage1.config 

# Config file copied from CFHTLS stage 2 dir - don't be hasty, 
# set initial date to the beginning of the week.

# Fail - 0 classifications found etc. Maybe mongo is broken?
# OK, trash old mongo and swipe the new one. Gulp! Can always just start from 
# half an hour ago for testing... First, rerun verbose, see whats happening?

# oops, all classifications have items=None, must have screwed up somewhere.
# To do one by one test, need to run python directly:

SWAP.py stage1.config

# OK, fixed bugs, survey vs project comparison now in operation.

# Good! Seems to be working OK. Test classifications (not on live site)
# mostly junk, see report in attic. Onwards!

# ======================================================================
# 2014-01-07 (Tuesday) 22:53 PST

# OK, start the agents at 20:00 GMT for the start of Stargazing Live:
# Need to trash mongo in old CFHTLS stage 2 dir.
# Do 5 million at a time for speed! 

SWIPE.csh spacewarp_2014-01-08.gz 

SWAPSHOP.csh -s VICS82 --startup --fast --config stage1.config 

# Wed Jan  8 01:14:32 PST 2014
# SWAP: updating all subjects with classifications made since 2014-01-07_20:00:00
# SWAP: interpreting up to 5000000  classifications...
# SWAP: ..................
# SWAP: total no. of classifications processed:  1235829
# ...
# SWAP: saving retiree subject Zooniverse IDs...
# SWAP: 2421 lines written to /Users/pjm/public_html/SpaceWarps/Science/analysis/VICS82/stage1/VICS82_2014-01-08_01:20:51/VICS82_2014-01-08_01:20:51_retire_these.txt
# SWAP: saving lens candidates...
# SWAP: 24 lines written to /Users/pjm/public_html/SpaceWarps/Science/analysis/VICS82/stage1/VICS82_2014-01-08_01:20:51/VICS82_2014-01-08_01:20:51_candidates.txt
# ...
# SWAP: From 11471 subjects classified,
# SWAP: 8654 candidates (with P > rejection) written to /Users/pjm/public_html/SpaceWarps/Science/analysis/VICS82/stage1/VICS82_2014-01-08_01:20:51/VICS82_2014-01-08_01:20:51_candidate_catalog.txt
# Wed Jan  8 02:04:03 PST 2014

# SWAP takes about 50 mins to do 1.2 million classifications. 40 mins per
# million.

# Only 11k subjects served?! DB problem?

# Low number of retirees; cascade plot shows a lot of images with high
# uncertainty, hanging out in the middle.

# 24 candidates with P > 0.95 - need to check these out!

SWAPSHOP.csh -s VICS82 --startup --fast --no-analysis --download 

# SWAPSHOP: in folder 'candidates',
# SWAPSHOP: downloading 24 images from
# ../VICS82_2014-01-08_01:20:51/VICS82_2014-01-08_01:20:51_candidate_catalog.txt...........................SWAPSHOP:
# ...done.
mv candidates candidates_P.gt.0.95

# Hmm - one or two mildly interesting but nothing remarkable. Try digging
# deeper, P > 0.10

# SWAPSHOP: downloading 87 images from ../VICS82_2014-01-08_01:20:51/VICS82_2014-01-08_01:20:51_candidate_catalog.txt

mv candidates candidates_P.gt.0.10

# Not much to be gained! Made galleries:

gallery.pl -pdf -x 1 -y 1 -t -o VICS82_1stmillion_P.gt.0.95.pdf \
  candidates_P.gt.0.95/*.png

gallery.pl -pdf -x 1 -y 1 -t -o VICS82_1stmillion_P.gt.0.10.pdf \
  candidates_P.gt.0.10/*.png
  
# Focus on P > 0.95.
# Highlights:

Cluster with several candidate lensed images; no obvious conjugate systems 
but some images are very red: 

  gallery.pl -pdf -x 1 -y 1 -t -o VICS82_1stmillion_Cluster.pdf \
    candidates_P.gt.0.10/ASW0009i4s.png

Several nearly-lensed quasars: quasars close to massive galaxies, some
possibly with faint counter-images buried in lens galaxy.

  gallery.pl -pdf -x 2 -y 2 -t -o VICS82_1stmillion_4NLQs.pdf \
    candidates_P.gt.0.10/ASW0009kg3.png \
    candidates_P.gt.0.10/ASW0009kj8.png \
    candidates_P.gt.0.10/ASW0009okd.png \
    candidates_P.gt.0.10/ASW0009pbd.png
  
Possible long blue arc:

  gallery.pl -pdf -x 1 -y 1 -t -o VICS82_1stmillion_LongArc.pdf \
    candidates_P.gt.0.10/ASW0009jxt.png
  
Short red arc:

  gallery.pl -pdf -x 1 -y 1 -t -o VICS82_1stmillion_ShortRedArc.pdf \
    candidates_P.gt.0.10/ASW0009jlw.png


# Miscellaneous, not yet SWAP or Talk-detected:

Double purple quasar?
   http://talk.spacewarps.org/#/subjects/ASW0009lgi

Aprajita's bright double:
   http://talk.spacewarps.org/#/subjects/ASW0009uo2
   
Jim's eyeball ring:
   http://talk.spacewarps.org/#/subjects/ASW0009io9
   02:09:41.3 +00:15:58.7

# BTW what else is nearby?

askSDSS -f -w 1 --hms 02:09:41.3 +00:15:58.7
# askSDSS: query the SDSS website for images, catalogues and spectra
# askSDSS: required position: 32.42208 0.26631
# askSDSS: TODO: make finding chart
# askSDSS: field size / arcmin: 1
# askSDSS: ra (J2000): 02 09 41.3
# askSDSS: dec (J2000): +00 15 58.7
# askSDSS: IAU name of search position: SDSSJ020941.3+001558.7
# askSDSS: downloading image...
# askSDSS: finding chart image:
#   SDSSJ020941.3+001558.7_1x1arcmin.jpg
# askSDSS: Explorer URL:
#   http://skyserver.sdss3.org/public/en/tools/chart/chart.asp?ra=32.42208&dec=0.26631&opt=G&
# askSDSS: all done

# Not much! :-) Here's the 40" SDSS view:

askSDSS -f -w 0.67 --hms 02:09:41.3 +00:15:58.7

# ======================================================================
# 2014-01-07 (Tuesday) 22:53 PST

# Second run, on 3 million classifications. Over-wrote tarball, so trash mongo
# and old dir.

\rm -rf spacewarp_2014-01-08 mongo

SWIPE.csh spacewarp_2014-01-08.gz 

SWAPSHOP.csh -s VICS82 --fast --download

# Started swiping at 0415. If my estimate of 3 hours is correct, it shoudl be
# done by 0800 PST = 1600 GMT 
# Finished at 0730 PST. Good!

# First, check for 0209:
grep ASW0009io9 VICS82_2014-01-08_10:35:11/VICS82_2014-01-08_10:35:11_candidate_catalog.txt 
# ASW0009io9  0.0000575  3       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019e4.png

# Bizarre - P < P0 by a factor of 3. Oh well, only 3 classifications.

wget -O ASW0009io9.png http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019e4.png

# Now then, candidates:

SWAPSHOP: in folder 'candidates',
SWAPSHOP: downloading 52 images from ../VICS82_2014-01-08_10:35:11/VICS82_2014-01-08_10:35:11_candidate_catalog.txt

mv candidates VICS82_2million_candidates_P.gt.0.95
gallery.pl -pdf -x 1 -y 1 -t -o VICS82_2million_candidates_P.gt.0.95.pdf \
  VICS82_2million_candidates_P.gt.0.95/*.png

# Nice arc:

VICS82_2million_candidates_P.gt.0.95/ASW0009dqb.png

# Copy report:

cp VICS82_stage1_report.pdf VICS82_2million_report.pdf

# Cascade looks *much* better! Some good rejection going on, and 39804
# subjecst now classified. Try pulling out systems above 1%:

SWAPSHOP.csh -s VICS82 --fast --no-analysis --download 

# 398 images! Cool. Browse these.
mv candidates VICS82_2million_candidates_P.gt.0.01
gallery.pl -pdf -x 2 -y 2 -t -o VICS82_2million_candidates_P.gt.0.01.pdf \
  VICS82_2million_candidates_P.gt.0.01/*.png

# Quite like this one:
ASW0009iov.png

# Grab these two:
  gallery.pl -pdf -x 1 -y 1 -t -o VICS82_2million_NiceArcs.pdf \
    VICS82_2million_candidates_P.gt.0.95/ASW0009dqb.png \
    VICS82_2million_candidates_P.gt.0.01/ASW0009iov.png

# From Christine: "2 red dots"
http://talk.spacewarps.org/#/subjects/ASW0009i91

# From Claude:
http://talk.spacewarps.org/#/subjects/ASW0009dk6

head -1 \
  VICS82_2014-01-08_10:35:11/VICS82_2014-01-08_10:35:11_candidate_catalog.txt ; \
grep -e ASW0009dqb -e ASW0009iov -e ASW0009io9 \
     -e ASW0009i91 -e ASW0009dk6 \
  VICS82_2014-01-08_10:35:11/VICS82_2014-01-08_10:35:11_candidate_catalog.txt 

# # zooid     P          Nclass  image
# ASW0009dqb  1.0000000  279       http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c0000de.png
# ASW0009i91  0.0000306  7       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0017c0.png
# ASW0009dk6  0.0007486  7       http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c000001.png
# ASW0009io9  0.0000575  3       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019e4.png
# ASW0009iov  0.0128811  46       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019fa.png

wget -O ASW0009dk6.png http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c000001.png
wget -O ASW0009i91.png http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0017c0.png 

# Retirements?

wc -l VICS82_2million_retire_these.txt
#     5745 VICS82_2million_retire_these.txt

# Sent to Michael.

# Best arcs for lenshunters:
  gallery.pl -pdf -x 1 -y 1 -t -o VICS82_2million_best.pdf \
    ASW0009io9.png \
    VICS82_2million_candidates_P.gt.0.95/ASW0009dqb.png \
    VICS82_2million_candidates_P.gt.0.01/ASW0009iov.png


# OK, on with the next batch!

# ======================================================================
# 2014-01-08 (Wednesday) 08:55 PST

\rm -rf spacewarp_2014-01-08 mongo

SWIPE.csh spacewarp_2014-01-08.gz 

SWAPSHOP.csh -s VICS82 --fast --download

Summary of output:

SWAP: total no. of classifications processed:  338074
SWAP: saving lens candidates...
SWAP: 69 lines written to /Users/pjm/public_html/SpaceWarps/Science/analysis/VICS82/stage1/VICS82_2014-01-08_15:29:15/VICS82_2014-01-08_15:29:15_candidates.txt
SWAPSHOP: if you want, you can go ahead and retire 10656 subjects with

# Cool. Report shows 2.7 million classifications of 41538 subjects by
# 38k users, 69 candidates, 18725 rejections. Plots very encouraging.

mv VICS82_stage1_report.pdf VICS82_2.7million_report.pdf
mv VICS82_stage1_retire_these.txt VICS82_2.7million_retire_these.txt
wc -l VICS82_2.7million_retire_these.txt
#   10656 VICS82_2.7million_retire_these.txt

# Quick look for new candidates:

mv candidates VICS82_2.7million_candidates_P.gt.0.95
gallery.pl -pdf -x 1 -y 1 -t -o VICS82_2.7million_candidates_P.gt.0.95.pdf \
  VICS82_2.7million_candidates_P.gt.0.95/*.png

# YES! 9io9 detected :-)
   http://talk.spacewarps.org/#/subjects/ASW0009io9

# Possibly interesting blue arcs:
   http://talk.spacewarps.org/#/subjects/ASW000a8ep

# Anu reports this one from Talk:
   http://talk.spacewarps.org/#/subjects/ASW0009l59
#   00:39:08.6 -00:58:28.1

head -1 \
   VICS82_2014-01-08_15:29:15/VICS82_2014-01-08_15:29:15_candidate_catalog.txt ; \
grep -e ASW0009io9 -e ASW0009l59 \
   VICS82_2014-01-08_15:29:15/VICS82_2014-01-08_15:29:15_candidate_catalog.txt
   
# # zooid     P          Nclass  image
# ASW0009l59  0.0000064  4       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c002668.png
# ASW0009io9  0.9640383  13       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019e4.png

# Again, 9l59 needs more classifications. Talk FTW!

# For now, make gallery of all best candidates - I count 6:

head -1 \
   VICS82_2014-01-08_15:29:15/VICS82_2014-01-08_15:29:15_candidate_catalog.txt ; \
grep -e ASW0009dqb \
     -e ASW0009iov \
     -e ASW0009io9 \
     -e ASW0009i91 \
     -e ASW0009dk6 \
     -e ASW0009l59 \
   VICS82_2014-01-08_15:29:15/VICS82_2014-01-08_15:29:15_candidate_catalog.txt

# # zooid     P          Nclass  image
# ASW0009dqb  1.0000000  288      http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c0000de.png
# ASW0009i91  0.0183210  16       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0017c0.png
# ASW0009dk6  0.5566131  11       http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c000001.png
# ASW0009l59  0.0000064  4        http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c002668.png
# ASW0009io9  0.9640383  13       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019e4.png
# ASW0009iov  0.0053120  51       http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019fa.png     

wget -O ASW0009dqb.png http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c0000de.png
wget -O ASW0009iov.png http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019fa.png     
wget -O ASW0009l59.png http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c002668.png


# Download these 
  gallery.pl -pdf -x 1 -y 1 -t -o VICS82_2.7million_Top5.pdf \
    ASW0009io9.png \
    ASW0009l59.png \
    ASW0009iov.png \
    ASW0009dqb.png \
    ASW0009dk6.png

# ======================================================================
# 2014-01-08 (Wednesday) 20:42 PST

\rm -rf spacewarp_2014-01-08*

SWIPE.csh spacewarp_2014-01-09.gz 

SWAPSHOP.csh -s VICS82 --fast --download

# Whoah - db is 21GB! SWAP runs very slowly - or even gets stuck on 
# db.find()? No - it couldnt connect to the mongo...
# RE-swipe! God-damnint. OK scratch that, got a new dump.
     

# ======================================================================
# 2014-01-09 (Thursday) 05:39 PST

SWIPE.csh spacewarp_2014-01-09.gz 

SWAPSHOP.csh -s VICS82 --fast --download

# OK, what have we got here?

SWAP: total no. of classifications processed:  2449799
# +2.7million = 5.1 million
# 55609 classification agents, 41998 subjects 

SWAP: saving retiree subject Zooniverse IDs...
SWAP: 36791 lines written to /Users/pjm/public_html/SpaceWarps/Science/analysis/VICS82/stage1/VICS82_2014-01-09_11:00:00/VICS82_2014-01-09_11:00:00_retire_these.txt
SWAP: saving lens candidates...
SWAP: 153 lines written to /Users/pjm/public_html/SpaceWarps/Science/analysis/VICS82/stage1/VICS82_2014-01-09_11:00:00/VICS82_2014-01-09_11:00:00_candidates.txt

# Cool! 37k subjects to be retired in total, 28655 still to do.
# Report: 

mv VICS82_stage1_report.pdf VICS82_5.1million_report.pdf
mv VICS82_stage1_retire_these.txt VICS82_5.1million_retire_these.txt

# 153 P.gt.0.95 candidates! Including some new ones, pulled these out by hand:

mv candidates VICS82_5.1million_candidates_P.gt.0.95

gallery.pl -pdf -x 2 -y 2 -t -o VICS82_5.1million_candidates_P.gt.0.95.pdf \
  VICS82_5.1million_candidates_P.gt.0.95/ASW*png

# Nice little red arc?
  http://talk.spacewarps.org/#/subjects/ASW000a2y7

# Blue fuzz under pair:
  http://talk.spacewarps.org/#/subjects/ASW0009dvs

# A little double?
  http://talk.spacewarps.org/#/subjects/ASW0009fht

# Little red arc? With extent plus counterimage?
  http://talk.spacewarps.org/#/subjects/ASW0009ifa

# Pink quad?
  http://talk.spacewarps.org/#/subjects/ASW0009klz

# Yellow! With blue fuzz underneath.
  http://talk.spacewarps.org/#/subjects/ASW0009vfi

# Combine with others:

head -1 \
  VICS82_2014-01-09_11:00:00/VICS82_2014-01-09_11:00:00_candidate_catalog.txt ; \
grep \
-e ASW0009io9 \
-e ASW0009l59 \
-e ASW0009iov \
-e ASW0009dqb \
-e ASW0009dk6 \
-e ASW000a2y7 \
-e ASW0009dvs \
-e ASW0009fht \
-e ASW0009ifa \
-e ASW0009klz \
-e ASW0009vfi \
  VICS82_2014-01-09_11:00:00/VICS82_2014-01-09_11:00:00_candidate_catalog.txt

# zooid     P          Nclass  image
ASW0009klz  0.9999979  24      http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0023b2.png
ASW0009dqb  1.0000000  288     http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c0000de.png
ASW0009dk6  0.9998838  46      http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c000001.png
ASW0009ifa  1.0000000  132     http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0018a1.png
ASW0009l59  1.0000000  363     http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c002668.png
ASW0009fht  1.0000000  119     http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c0009cc.png
ASW0009vfi  0.9844575  25      http://spacewarps.org/subjects/standard/52c1c4d03ae740492c005a79.png
ASW0009io9  1.0000000  51      http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019e4.png
ASW000a2y7  0.9999997  108     http://spacewarps.org/subjects/standard/52c1c4d03ae740492c00808a.png
ASW0009dvs  0.9959316  43      http://spacewarps.org/subjects/standard/52c1c4ce3ae740492c0001a3.png
ASW0009iov  0.9999985  127     http://spacewarps.org/subjects/standard/52c1c4cf3ae740492c0019fa.png

# Check out those probabilities!!
# OK, make gallery:

gallery.pl -pdf -x 1 -y 1 -t -o VICS82_5.1million_Top11.pdf \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009io9.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009l59.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009klz.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009dqb.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009dk6.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009ifa.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009fht.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009vfi.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW000a2y7.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009dvs.png \
   VICS82_5.1million_candidates_P.gt.0.95/ASW0009iov.png

# OK, send all to team.

# ======================================================================
# 2014-01-14 (Tuesday) 06:48 PST

\rm -rf spacewarp_2014-01-09*

SWIPE.csh spacewarp_2014-01-14.gz 

SWAPSHOP.csh -s VICS82 --fast --download

# From report:

# 7.3 million classifications, 71894 classifiers, 196 candidates.

mv VICS82_stage1_report.pdf VICS82_7.3million_report.pdf
mv candidates VICS82_7.3million_candidates_P.gt.0.95
mv VICS82_stage1_retire_these.txt VICS82_7.3million_retire_these.txt

# Gallery of 196 candidates:
gallery.pl -pdf -x 2 -y 2 -t -o VICS82_7.3million_candidates_P.gt.0.95.pdf \
  VICS82_7.3million_candidates_P.gt.0.95/ASW*png

# Nice, but short, red arcs:
  http://talk.spacewarps.org/#/subjects/ASW0009hu7

# That's about it.

# ======================================================================
# 2014-01-15 (Wednesday) 10:01 PST

# Is this the last SWAP run?

\rm -rf spacewarp_2014-01-14*

SWIPE.csh spacewarp_2014-01-15.gz 

SWAPSHOP.csh -s VICS82 --fast --download

# From report:

# 7.3 million classifications, 71895 classifiers, 196 candidates.
# Looks like its converged.

mkdir -p 7.3million
mv VICS82_stage1_report.pdf 7.3million/VICS82_7.3million_report.pdf
mv candidates 7.3million/VICS82_7.3million_candidates_P.gt.0.95
mv VICS82_stage1_retire_these.txt 7.3million/VICS82_7.3million_retire_these.txt

# Gallery of 196 candidates:
gallery.pl -pdf -x 2 -y 2 -t -o 7.3million/VICS82_7.3million_candidates_P.gt.0.95.pdf \
  7.3million/VICS82_7.3million_candidates_P.gt.0.95/ASW*png

# Nice, but short, red arcs:
  http://talk.spacewarps.org/#/subjects/ASW0009hu7

# Check candidate catalog:

cp VICS82_2014-01-15_09:36:47/VICS82_2014-01-15_09:36:47_candidate_catalog.txt \
   7.3million/VICS82_7.3million_candidate_catalog.txt 

# Only 19 have fewer than 20 classificatiosn, only 1 has less than 10.

# ======================================================================

# Running list of CFHTLS stage 2 candidates!

# Select at P > 0.95
#
# 43 candidates, most of them known, one or two false positives, some new lenses!

# Good candidates:
http://talk.spacewarps.org/#/subjects/ASW0007xrs   # Commenters disagree
http://talk.spacewarps.org/#/subjects/ASW0007h27   # 2 possible lenses
http://talk.spacewarps.org/#/subjects/ASW0005o38   # Nice galaxy-scale arc
http://talk.spacewarps.org/#/subjects/ASW0004pbz   # Tiny binary lens
http://talk.spacewarps.org/#/subjects/ASW0004nan   # Bright UV arc under LRG
http://talk.spacewarps.org/#/subjects/ASW00008a0   # Thin arcs, multiple imaging
http://talk.spacewarps.org/#/subjects/ASW0009bbq   # Faint cluster arc
http://talk.spacewarps.org/#/subjects/ASW00096rm  # Nice tiny quad
http://talk.spacewarps.org/#/subjects/ASW000993q   # Cluster lens, plus galaxy pertuber
http://talk.spacewarps.org/#/subjects/ASW0006i2r   # Nice arc next to LRG
http://talk.spacewarps.org/#/subjects/ASW0004106   # Sheared arc! 3-plane lens :-)
http://talk.spacewarps.org/#/subjects/ASW0005vog   # Binary lens, faint arc with knot

# False positives:
http://talk.spacewarps.org/#/subjects/ASW0003ox0   # Dashboard shows it to be a merging spiral
http://talk.spacewarps.org/#/subjects/ASW000279i   # Nearby dwarf with companions
http://talk.spacewarps.org/#/subjects/ASW00032ae   # 3-way merger, plus orange/blue spiral
http://talk.spacewarps.org/#/subjects/ASW00011ls   # Spiral/Ring?

# Unknown:
http://talk.spacewarps.org/#/subjects/ASW0001rcc   # Wierd g-band circular blob, bigger than i/r
http://talk.spacewarps.org/#/subjects/ASW0006noe   # Promising but needs more work
http://talk.spacewarps.org/#/subjects/ASW0009ans   # Bright UV arc, 2 or 3 blobs?
http://talk.spacewarps.org/#/subjects/ASW0000hng   # Odd U-shaped arc, v bright star nearby
http://talk.spacewarps.org/#/subjects/ASW00024id   # Weird high radius arc, ring galaxy?

# ======================================================================
# 2014-01-30

# Zooming in on the good candidates:

set goods = `grep 'http://talk' ../../doc/notes/notes-pjm.txt | grep '# ' | head -12 | cut -d'/' -f6 | awk '{printf "candidates/%s.png\n", $1}' | sort`

mkdir goods
cp $goods goods/.

# Now zooms! Estimate fractional central x and y from preview

set images = ( \
ASW0004nan.png \
ASW0004pbz.png \
ASW0005o38.png \
ASW0004dv8.png \
ASW0006i2r.png \
ASW0007h27.png \
ASW0007xrs.png \
ASW00008a0.png \
ASW0009bbq.png \
ASW00096rm.png \
ASW000993q.png \
ASW0004106.png \
)

set x = (\
0.75 \
0.7 \
0.7 \
0.45 \
0.8 \
0.35 \
0.2 \
0.75 \
0.6 \
0.75 \
0.55 \
0.45 \
)

set y = ( \
0.65 \
0.45 \
0.3 \
0.8 \
0.75 \
0.85 \
0.87 \
0.2 \
0.85 \
0.8 \
0.75 \
0.7 \
)

foreach k ( `seq $#images` )
  set image = goods/$images[$k]
  set zoom = ${image:r}_zoom.png 
  set i = `echo $x[$k] | awk '{printf "%d\n", $1*440 - 50}'`
  set j = `echo $y[$k] | awk '{printf "%d\n", $1*440 - 50}'`
  set string = "100x100+$i+$j"
  convert -crop $string $image $zoom
  du -h $zoom
end

# Good!






